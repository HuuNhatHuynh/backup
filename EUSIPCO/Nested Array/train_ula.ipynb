{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from utils import *\n",
    "from models import *\n",
    "from tqdm import tqdm\n",
    "\n",
    "dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 3\n",
    "m = 8\n",
    "t = 200\n",
    "n = 2000\n",
    "snr = 0\n",
    "lamda = 0.2\n",
    "distance = 0.1\n",
    "qpsk = False\n",
    "coherent = False\n",
    "\n",
    "array = ULA(m, lamda)\n",
    "array.build_sensor_positions(distance)\n",
    "array.build_array_manifold()\n",
    "\n",
    "observations, angles = generate_data(n, t, d, snr, snr, array, qpsk, coherent)\n",
    "path = 'few_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbEpoches = 300\n",
    "lr = 1e-2\n",
    "wd = 1e-8\n",
    "\n",
    "batchSize = 256\n",
    "\n",
    "x_train, x_valid, theta_train, theta_valid = train_test_split(observations, angles, test_size=0.2)\n",
    "\n",
    "train_set = DATASET(x_train, theta_train)\n",
    "valid_set = DATASET(x_valid, theta_valid)\n",
    "\n",
    "train_func = RMSPE(d, device=dev)\n",
    "valid_func = RMSPE(d, device=dev)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batchSize, shuffle=True)\n",
    "valid_loader = DataLoader(valid_set, batch_size=batchSize, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/300 [00:00<00:42,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0: loss training = 0.5786921509674617, best validation = 0.4752357304096222\n",
      "iteration 1: loss training = 0.484046003648213, best validation = 0.45049795508384705\n",
      "iteration 2: loss training = 0.46416995355061125, best validation = 0.4428417682647705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 5/300 [00:00<00:32,  9.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 3: loss training = 0.4568688826901572, best validation = 0.4428417682647705\n",
      "iteration 4: loss training = 0.44939009632383076, best validation = 0.4428417682647705\n",
      "iteration 5: loss training = 0.4476754197052547, best validation = 0.4424890726804733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 9/300 [00:00<00:26, 11.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 6: loss training = 0.4390663078853062, best validation = 0.44052062928676605\n",
      "iteration 7: loss training = 0.43209204929215567, best validation = 0.44052062928676605\n",
      "iteration 8: loss training = 0.4228315608842032, best validation = 0.4380560368299484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 11/300 [00:01<00:24, 11.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 9: loss training = 0.4248017540999821, best validation = 0.4333367496728897\n",
      "iteration 10: loss training = 0.41583159991673063, best validation = 0.4317473918199539\n",
      "iteration 11: loss training = 0.4045722016266414, best validation = 0.4193747192621231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 15/300 [00:01<00:22, 12.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 12: loss training = 0.3977302185126713, best validation = 0.41545331478118896\n",
      "iteration 13: loss training = 0.39241647720336914, best validation = 0.41545331478118896\n",
      "iteration 14: loss training = 0.39037668279239107, best validation = 0.40886878967285156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 17/300 [00:01<00:21, 13.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 15: loss training = 0.3809290698596409, best validation = 0.40738777816295624\n",
      "iteration 16: loss training = 0.37837121742112295, best validation = 0.4062587767839432\n",
      "iteration 17: loss training = 0.3807571700641087, best validation = 0.40391457080841064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 21/300 [00:01<00:20, 13.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 18: loss training = 0.3756543695926666, best validation = 0.4017571806907654\n",
      "iteration 19: loss training = 0.3710239657333919, best validation = 0.3985210955142975\n",
      "iteration 20: loss training = 0.36609817828450886, best validation = 0.3985210955142975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 23/300 [00:01<00:20, 13.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 21: loss training = 0.3585974190916334, best validation = 0.3985210955142975\n",
      "iteration 22: loss training = 0.3608521819114685, best validation = 0.3966952860355377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 25/300 [00:02<00:23, 11.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 23: loss training = 0.3553098014422825, best validation = 0.3966952860355377\n",
      "iteration 24: loss training = 0.3530949737344469, best validation = 0.3926200568675995\n",
      "iteration 25: loss training = 0.34860189471926006, best validation = 0.3893306851387024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 29/300 [00:02<00:21, 12.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 26: loss training = 0.33939699615750996, best validation = 0.3857140392065048\n",
      "iteration 27: loss training = 0.33689941678728375, best validation = 0.3783581107854843\n",
      "iteration 28: loss training = 0.33114759411130634, best validation = 0.3708801120519638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 31/300 [00:02<00:20, 12.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 29: loss training = 0.32397336193493437, best validation = 0.3689565658569336\n",
      "iteration 30: loss training = 0.31809395125934053, best validation = 0.36340469121932983\n",
      "iteration 31: loss training = 0.3179848577295031, best validation = 0.36038585007190704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 35/300 [00:02<00:20, 12.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 32: loss training = 0.311565637588501, best validation = 0.35974903404712677\n",
      "iteration 33: loss training = 0.30786574312618803, best validation = 0.35831277072429657\n",
      "iteration 34: loss training = 0.3008561304637364, best validation = 0.35822683572769165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 37/300 [00:03<00:20, 12.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 35: loss training = 0.29815233179501127, best validation = 0.35822683572769165\n",
      "iteration 36: loss training = 0.299314626625606, best validation = 0.35745929181575775\n",
      "iteration 37: loss training = 0.2938208452292851, best validation = 0.3572627902030945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 41/300 [00:03<00:19, 13.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 38: loss training = 0.2952635245663779, best validation = 0.356000691652298\n",
      "iteration 39: loss training = 0.28884997963905334, best validation = 0.356000691652298\n",
      "iteration 40: loss training = 0.2877547357763563, best validation = 0.35585354268550873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 43/300 [00:03<00:19, 13.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 41: loss training = 0.28900828106062754, best validation = 0.35585354268550873\n",
      "iteration 42: loss training = 0.2836122385093144, best validation = 0.35585354268550873\n",
      "iteration 43: loss training = 0.2852025202342442, best validation = 0.35585354268550873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 47/300 [00:03<00:18, 13.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 44: loss training = 0.2802932560443878, best validation = 0.35585354268550873\n",
      "iteration 45: loss training = 0.28181768315179007, best validation = 0.35585354268550873\n",
      "iteration 46: loss training = 0.2773824632167816, best validation = 0.3558243364095688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 49/300 [00:04<00:18, 13.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 47: loss training = 0.2798006364277431, best validation = 0.3543839603662491\n",
      "iteration 48: loss training = 0.27944043278694153, best validation = 0.3543839603662491\n",
      "iteration 49: loss training = 0.27547845244407654, best validation = 0.3543839603662491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 53/300 [00:04<00:18, 13.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 50: loss training = 0.2754521838256291, best validation = 0.3543839603662491\n",
      "iteration 51: loss training = 0.27329947693007334, best validation = 0.3543839603662491\n",
      "iteration 52: loss training = 0.27356700386319843, best validation = 0.3543839603662491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 55/300 [00:04<00:17, 13.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 53: loss training = 0.2696948860372816, best validation = 0.3543839603662491\n",
      "iteration 54: loss training = 0.2714280443532126, best validation = 0.3543839603662491\n",
      "iteration 55: loss training = 0.268357800585883, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 59/300 [00:04<00:17, 13.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 56: loss training = 0.2634892932006291, best validation = 0.35417303442955017\n",
      "iteration 57: loss training = 0.2633422932454518, best validation = 0.35417303442955017\n",
      "iteration 58: loss training = 0.2606639266014099, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 61/300 [00:04<00:17, 13.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 59: loss training = 0.26362953441483633, best validation = 0.35417303442955017\n",
      "iteration 60: loss training = 0.2580160456044333, best validation = 0.35417303442955017\n",
      "iteration 61: loss training = 0.25884406907217844, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 65/300 [00:05<00:16, 13.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 62: loss training = 0.25597246416977476, best validation = 0.35417303442955017\n",
      "iteration 63: loss training = 0.2510047512395041, best validation = 0.35417303442955017\n",
      "iteration 64: loss training = 0.25316262032304493, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 67/300 [00:05<00:17, 13.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 65: loss training = 0.2533787808247975, best validation = 0.35417303442955017\n",
      "iteration 66: loss training = 0.25354281280721935, best validation = 0.35417303442955017\n",
      "iteration 67: loss training = 0.25414349351610455, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 71/300 [00:05<00:16, 13.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 68: loss training = 0.25438450276851654, best validation = 0.35417303442955017\n",
      "iteration 69: loss training = 0.25109609748635975, best validation = 0.35417303442955017\n",
      "iteration 70: loss training = 0.250957082424845, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 73/300 [00:05<00:16, 13.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 71: loss training = 0.2504887453147343, best validation = 0.35417303442955017\n",
      "iteration 72: loss training = 0.25469658630234854, best validation = 0.35417303442955017\n",
      "iteration 73: loss training = 0.24856305973870413, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 77/300 [00:06<00:16, 13.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 74: loss training = 0.25125862870897564, best validation = 0.35417303442955017\n",
      "iteration 75: loss training = 0.2462983216558184, best validation = 0.35417303442955017\n",
      "iteration 76: loss training = 0.24977568217686244, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 79/300 [00:06<00:16, 13.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 77: loss training = 0.2521988387618746, best validation = 0.35417303442955017\n",
      "iteration 78: loss training = 0.24639674169676645, best validation = 0.35417303442955017\n",
      "iteration 79: loss training = 0.24825769449983323, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 83/300 [00:06<00:15, 13.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 80: loss training = 0.24740866252354213, best validation = 0.35417303442955017\n",
      "iteration 81: loss training = 0.247196369937488, best validation = 0.35417303442955017\n",
      "iteration 82: loss training = 0.24898915418556758, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 85/300 [00:06<00:15, 13.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 83: loss training = 0.24540838173457555, best validation = 0.35417303442955017\n",
      "iteration 84: loss training = 0.24786484241485596, best validation = 0.35417303442955017\n",
      "iteration 85: loss training = 0.24645101172583445, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 89/300 [00:06<00:15, 13.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 86: loss training = 0.24735606355326517, best validation = 0.35417303442955017\n",
      "iteration 87: loss training = 0.2496219745704106, best validation = 0.35417303442955017\n",
      "iteration 88: loss training = 0.2440671239580427, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 91/300 [00:07<00:15, 13.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 89: loss training = 0.24059447859014785, best validation = 0.35417303442955017\n",
      "iteration 90: loss training = 0.24766665484224046, best validation = 0.35417303442955017\n",
      "iteration 91: loss training = 0.24452921748161316, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 95/300 [00:07<00:15, 13.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 92: loss training = 0.2439156493970326, best validation = 0.35417303442955017\n",
      "iteration 93: loss training = 0.24686286066259658, best validation = 0.35417303442955017\n",
      "iteration 94: loss training = 0.2437193649155753, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 97/300 [00:07<00:15, 13.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 95: loss training = 0.24604808858462743, best validation = 0.35417303442955017\n",
      "iteration 96: loss training = 0.2444752539907183, best validation = 0.35417303442955017\n",
      "iteration 97: loss training = 0.2448377481528691, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 101/300 [00:07<00:14, 13.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 98: loss training = 0.2463109110082899, best validation = 0.35417303442955017\n",
      "iteration 99: loss training = 0.24444799338068282, best validation = 0.35417303442955017\n",
      "iteration 100: loss training = 0.24495196768215724, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 103/300 [00:07<00:14, 13.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 101: loss training = 0.2463120094367436, best validation = 0.35417303442955017\n",
      "iteration 102: loss training = 0.24182863320623124, best validation = 0.35417303442955017\n",
      "iteration 103: loss training = 0.24494908537183488, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 107/300 [00:08<00:14, 13.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 104: loss training = 0.2390668307031904, best validation = 0.35417303442955017\n",
      "iteration 105: loss training = 0.24368764460086823, best validation = 0.35417303442955017\n",
      "iteration 106: loss training = 0.24491457853998458, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 109/300 [00:08<00:14, 13.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 107: loss training = 0.24383927030222757, best validation = 0.35417303442955017\n",
      "iteration 108: loss training = 0.24496743083000183, best validation = 0.35417303442955017\n",
      "iteration 109: loss training = 0.24332856493336813, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 113/300 [00:08<00:14, 13.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 110: loss training = 0.24076307671410696, best validation = 0.35417303442955017\n",
      "iteration 111: loss training = 0.24505473460469926, best validation = 0.35417303442955017\n",
      "iteration 112: loss training = 0.24571619502135686, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 115/300 [00:08<00:13, 13.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 113: loss training = 0.24128887057304382, best validation = 0.35417303442955017\n",
      "iteration 114: loss training = 0.2405732465641839, best validation = 0.35417303442955017\n",
      "iteration 115: loss training = 0.243964712534632, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 119/300 [00:09<00:13, 13.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 116: loss training = 0.24135310522147588, best validation = 0.35417303442955017\n",
      "iteration 117: loss training = 0.24333550248827254, best validation = 0.35417303442955017\n",
      "iteration 118: loss training = 0.2440745426075799, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 121/300 [00:09<00:13, 13.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 119: loss training = 0.23903813106673105, best validation = 0.35417303442955017\n",
      "iteration 120: loss training = 0.24198604268687113, best validation = 0.35417303442955017\n",
      "iteration 121: loss training = 0.24254094915730612, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 125/300 [00:09<00:13, 13.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 122: loss training = 0.24420349725655147, best validation = 0.35417303442955017\n",
      "iteration 123: loss training = 0.24278736965996878, best validation = 0.35417303442955017\n",
      "iteration 124: loss training = 0.2426197294678007, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 127/300 [00:09<00:12, 13.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 125: loss training = 0.23986711246626718, best validation = 0.35417303442955017\n",
      "iteration 126: loss training = 0.24113651471478598, best validation = 0.35417303442955017\n",
      "iteration 127: loss training = 0.24241894483566284, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 131/300 [00:10<00:12, 13.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 128: loss training = 0.2429089035306658, best validation = 0.35417303442955017\n",
      "iteration 129: loss training = 0.23979235759803227, best validation = 0.35417303442955017\n",
      "iteration 130: loss training = 0.24355068164212362, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 133/300 [00:10<00:12, 13.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 131: loss training = 0.24206484428473882, best validation = 0.35417303442955017\n",
      "iteration 132: loss training = 0.24494674163205282, best validation = 0.35417303442955017\n",
      "iteration 133: loss training = 0.24463031334536417, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 137/300 [00:10<00:12, 13.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 134: loss training = 0.2408211933715003, best validation = 0.35417303442955017\n",
      "iteration 135: loss training = 0.243179623569761, best validation = 0.35417303442955017\n",
      "iteration 136: loss training = 0.23937798823629106, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 139/300 [00:10<00:11, 13.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 137: loss training = 0.24350486482892716, best validation = 0.35417303442955017\n",
      "iteration 138: loss training = 0.24241243728569575, best validation = 0.35417303442955017\n",
      "iteration 139: loss training = 0.23796432146004268, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 143/300 [00:10<00:11, 13.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 140: loss training = 0.2401180522782462, best validation = 0.35417303442955017\n",
      "iteration 141: loss training = 0.2464589583022254, best validation = 0.35417303442955017\n",
      "iteration 142: loss training = 0.2408749567610877, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 145/300 [00:11<00:11, 13.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 143: loss training = 0.24285615342003958, best validation = 0.35417303442955017\n",
      "iteration 144: loss training = 0.2418885337454932, best validation = 0.35417303442955017\n",
      "iteration 145: loss training = 0.24293245588030135, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 149/300 [00:11<00:10, 13.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 146: loss training = 0.24337897981916154, best validation = 0.35417303442955017\n",
      "iteration 147: loss training = 0.24080772485051835, best validation = 0.35417303442955017\n",
      "iteration 148: loss training = 0.24418306350708008, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 151/300 [00:11<00:10, 13.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 149: loss training = 0.24516324060303823, best validation = 0.35417303442955017\n",
      "iteration 150: loss training = 0.24277792232377188, best validation = 0.35417303442955017\n",
      "iteration 151: loss training = 0.24259380783353532, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 155/300 [00:11<00:10, 14.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 152: loss training = 0.2426156039748873, best validation = 0.35417303442955017\n",
      "iteration 153: loss training = 0.24238889345100947, best validation = 0.35417303442955017\n",
      "iteration 154: loss training = 0.2398394857134138, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 157/300 [00:11<00:10, 13.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 155: loss training = 0.2440251729318074, best validation = 0.35417303442955017\n",
      "iteration 156: loss training = 0.24520444657121385, best validation = 0.35417303442955017\n",
      "iteration 157: loss training = 0.24374531848090036, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 161/300 [00:12<00:10, 13.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 158: loss training = 0.2403490607227598, best validation = 0.35417303442955017\n",
      "iteration 159: loss training = 0.2438029944896698, best validation = 0.35417303442955017\n",
      "iteration 160: loss training = 0.2443620881864003, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 163/300 [00:12<00:09, 13.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 161: loss training = 0.24276521801948547, best validation = 0.35417303442955017\n",
      "iteration 162: loss training = 0.23820913689477102, best validation = 0.35417303442955017\n",
      "iteration 163: loss training = 0.23899577132293157, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 165/300 [00:12<00:09, 13.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 164: loss training = 0.24428534294877732, best validation = 0.35417303442955017\n",
      "iteration 165: loss training = 0.2410211775984083, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 169/300 [00:12<00:10, 12.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 166: loss training = 0.2446452613387789, best validation = 0.35417303442955017\n",
      "iteration 167: loss training = 0.24307925360543386, best validation = 0.35417303442955017\n",
      "iteration 168: loss training = 0.24135031870433263, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 171/300 [00:13<00:09, 12.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 169: loss training = 0.24181828115667617, best validation = 0.35417303442955017\n",
      "iteration 170: loss training = 0.2441547725881849, best validation = 0.35417303442955017\n",
      "iteration 171: loss training = 0.23888379335403442, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 175/300 [00:13<00:09, 13.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 172: loss training = 0.24111150630882808, best validation = 0.35417303442955017\n",
      "iteration 173: loss training = 0.24210187579904283, best validation = 0.35417303442955017\n",
      "iteration 174: loss training = 0.24372550419398717, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 177/300 [00:13<00:09, 13.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 175: loss training = 0.24066880345344543, best validation = 0.35417303442955017\n",
      "iteration 176: loss training = 0.24225584736892156, best validation = 0.35417303442955017\n",
      "iteration 177: loss training = 0.24545957786696299, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 181/300 [00:13<00:08, 13.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 178: loss training = 0.2429139635392598, best validation = 0.35417303442955017\n",
      "iteration 179: loss training = 0.24348980614117213, best validation = 0.35417303442955017\n",
      "iteration 180: loss training = 0.24180151522159576, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 183/300 [00:13<00:08, 13.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 181: loss training = 0.24631166883877345, best validation = 0.35417303442955017\n",
      "iteration 182: loss training = 0.23920503684452601, best validation = 0.35417303442955017\n",
      "iteration 183: loss training = 0.24392791731016977, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 187/300 [00:14<00:08, 13.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 184: loss training = 0.2419579667704446, best validation = 0.35417303442955017\n",
      "iteration 185: loss training = 0.2406055416379656, best validation = 0.35417303442955017\n",
      "iteration 186: loss training = 0.24543100808347976, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 189/300 [00:14<00:08, 13.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 187: loss training = 0.24294439171041762, best validation = 0.35417303442955017\n",
      "iteration 188: loss training = 0.24582799204758235, best validation = 0.35417303442955017\n",
      "iteration 189: loss training = 0.2459432887179511, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 193/300 [00:14<00:07, 13.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 190: loss training = 0.23908530601433345, best validation = 0.35417303442955017\n",
      "iteration 191: loss training = 0.24230948729174479, best validation = 0.35417303442955017\n",
      "iteration 192: loss training = 0.2433943258864539, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 195/300 [00:14<00:07, 13.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 193: loss training = 0.24081391521862575, best validation = 0.35417303442955017\n",
      "iteration 194: loss training = 0.2424578879560743, best validation = 0.35417303442955017\n",
      "iteration 195: loss training = 0.24077716682638442, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 199/300 [00:15<00:07, 12.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 196: loss training = 0.2415487744978496, best validation = 0.35417303442955017\n",
      "iteration 197: loss training = 0.24329119707856858, best validation = 0.35417303442955017\n",
      "iteration 198: loss training = 0.2458907493523189, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 201/300 [00:15<00:07, 12.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 199: loss training = 0.2422412782907486, best validation = 0.35417303442955017\n",
      "iteration 200: loss training = 0.24302851302283152, best validation = 0.35417303442955017\n",
      "iteration 201: loss training = 0.24249033417020524, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 205/300 [00:15<00:07, 13.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 202: loss training = 0.23990746481078012, best validation = 0.35417303442955017\n",
      "iteration 203: loss training = 0.24495033281190054, best validation = 0.35417303442955017\n",
      "iteration 204: loss training = 0.2425564421074731, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 207/300 [00:15<00:06, 13.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 205: loss training = 0.2397321547780718, best validation = 0.35417303442955017\n",
      "iteration 206: loss training = 0.2427806258201599, best validation = 0.35417303442955017\n",
      "iteration 207: loss training = 0.24084995687007904, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 211/300 [00:16<00:06, 13.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 208: loss training = 0.2418642512389592, best validation = 0.35417303442955017\n",
      "iteration 209: loss training = 0.2452373547213418, best validation = 0.35417303442955017\n",
      "iteration 210: loss training = 0.24131491567407334, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 213/300 [00:16<00:06, 13.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 211: loss training = 0.23951231156076705, best validation = 0.35417303442955017\n",
      "iteration 212: loss training = 0.241177179983684, best validation = 0.35417303442955017\n",
      "iteration 213: loss training = 0.2394068113395146, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 217/300 [00:16<00:06, 13.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 214: loss training = 0.2472900194781167, best validation = 0.35417303442955017\n",
      "iteration 215: loss training = 0.24177715182304382, best validation = 0.35417303442955017\n",
      "iteration 216: loss training = 0.24326533717768534, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 219/300 [00:16<00:05, 13.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 217: loss training = 0.24207924093518937, best validation = 0.35417303442955017\n",
      "iteration 218: loss training = 0.24297640579087393, best validation = 0.35417303442955017\n",
      "iteration 219: loss training = 0.24215704841273172, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 223/300 [00:16<00:05, 13.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 220: loss training = 0.2446699163743428, best validation = 0.35417303442955017\n",
      "iteration 221: loss training = 0.24128037691116333, best validation = 0.35417303442955017\n",
      "iteration 222: loss training = 0.24073905604226248, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 225/300 [00:17<00:05, 12.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 223: loss training = 0.24048153843198503, best validation = 0.35417303442955017\n",
      "iteration 224: loss training = 0.24302210765225546, best validation = 0.35417303442955017\n",
      "iteration 225: loss training = 0.23963714497429983, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 229/300 [00:17<00:05, 13.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 226: loss training = 0.23933605423995427, best validation = 0.35417303442955017\n",
      "iteration 227: loss training = 0.24194809794425964, best validation = 0.35417303442955017\n",
      "iteration 228: loss training = 0.24282638728618622, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 231/300 [00:17<00:05, 13.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 229: loss training = 0.24390420743397304, best validation = 0.35417303442955017\n",
      "iteration 230: loss training = 0.2375799013035638, best validation = 0.35417303442955017\n",
      "iteration 231: loss training = 0.24301469326019287, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 235/300 [00:17<00:04, 13.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 232: loss training = 0.24443620443344116, best validation = 0.35417303442955017\n",
      "iteration 233: loss training = 0.2384371885231563, best validation = 0.35417303442955017\n",
      "iteration 234: loss training = 0.24420879568372453, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 237/300 [00:17<00:05, 12.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 235: loss training = 0.2404014446905681, best validation = 0.35417303442955017\n",
      "iteration 236: loss training = 0.24262447016579763, best validation = 0.35417303442955017\n",
      "iteration 237: loss training = 0.24202505392687662, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 241/300 [00:18<00:04, 12.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 238: loss training = 0.24231754669121333, best validation = 0.35417303442955017\n",
      "iteration 239: loss training = 0.2430682203599385, best validation = 0.35417303442955017\n",
      "iteration 240: loss training = 0.24219404586723872, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 243/300 [00:18<00:04, 13.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 241: loss training = 0.24459911670003617, best validation = 0.35417303442955017\n",
      "iteration 242: loss training = 0.24434072630746023, best validation = 0.35417303442955017\n",
      "iteration 243: loss training = 0.2415639055626733, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 247/300 [00:18<00:03, 13.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 244: loss training = 0.24622502710138047, best validation = 0.35417303442955017\n",
      "iteration 245: loss training = 0.24629473686218262, best validation = 0.35417303442955017\n",
      "iteration 246: loss training = 0.23782590883118765, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 249/300 [00:18<00:03, 13.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 247: loss training = 0.2432441200528826, best validation = 0.35417303442955017\n",
      "iteration 248: loss training = 0.2411154167992728, best validation = 0.35417303442955017\n",
      "iteration 249: loss training = 0.24223043876034872, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 253/300 [00:19<00:03, 14.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 250: loss training = 0.24521845153399877, best validation = 0.35417303442955017\n",
      "iteration 251: loss training = 0.24054054915905, best validation = 0.35417303442955017\n",
      "iteration 252: loss training = 0.24203835427761078, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 255/300 [00:19<00:03, 14.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 253: loss training = 0.24250281495707376, best validation = 0.35417303442955017\n",
      "iteration 254: loss training = 0.2391452874456133, best validation = 0.35417303442955017\n",
      "iteration 255: loss training = 0.24298048870904104, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 259/300 [00:19<00:02, 14.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 256: loss training = 0.24345918212618148, best validation = 0.35417303442955017\n",
      "iteration 257: loss training = 0.24462912338120596, best validation = 0.35417303442955017\n",
      "iteration 258: loss training = 0.24467098074299948, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 261/300 [00:19<00:02, 14.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 259: loss training = 0.24202624814850943, best validation = 0.35417303442955017\n",
      "iteration 260: loss training = 0.2417021244764328, best validation = 0.35417303442955017\n",
      "iteration 261: loss training = 0.23982195556163788, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 265/300 [00:19<00:02, 14.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 262: loss training = 0.23935229863439286, best validation = 0.35417303442955017\n",
      "iteration 263: loss training = 0.24134006244795664, best validation = 0.35417303442955017\n",
      "iteration 264: loss training = 0.24298536351748876, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 267/300 [00:20<00:02, 14.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 265: loss training = 0.2431649544409343, best validation = 0.35417303442955017\n",
      "iteration 266: loss training = 0.2410425501210349, best validation = 0.35417303442955017\n",
      "iteration 267: loss training = 0.2440860186304365, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 271/300 [00:20<00:02, 14.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 268: loss training = 0.24391135573387146, best validation = 0.35417303442955017\n",
      "iteration 269: loss training = 0.241349458694458, best validation = 0.35417303442955017\n",
      "iteration 270: loss training = 0.24337645513670786, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 273/300 [00:20<00:01, 14.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 271: loss training = 0.24404311605862208, best validation = 0.35417303442955017\n",
      "iteration 272: loss training = 0.2413125272308077, best validation = 0.35417303442955017\n",
      "iteration 273: loss training = 0.24003250684056962, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 277/300 [00:20<00:01, 14.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 274: loss training = 0.2396454576935087, best validation = 0.35417303442955017\n",
      "iteration 275: loss training = 0.2423561406987054, best validation = 0.35417303442955017\n",
      "iteration 276: loss training = 0.24468196077006205, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 279/300 [00:20<00:01, 14.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 277: loss training = 0.24202714647565568, best validation = 0.35417303442955017\n",
      "iteration 278: loss training = 0.24100572296551295, best validation = 0.35417303442955017\n",
      "iteration 279: loss training = 0.2420818316084998, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 283/300 [00:21<00:01, 14.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 280: loss training = 0.24047742571149552, best validation = 0.35417303442955017\n",
      "iteration 281: loss training = 0.24192206774439132, best validation = 0.35417303442955017\n",
      "iteration 282: loss training = 0.2423317496265684, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 285/300 [00:21<00:01, 14.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 283: loss training = 0.2468894783939634, best validation = 0.35417303442955017\n",
      "iteration 284: loss training = 0.24669270856039865, best validation = 0.35417303442955017\n",
      "iteration 285: loss training = 0.24197267421654292, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 289/300 [00:21<00:00, 13.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 286: loss training = 0.24074981255190714, best validation = 0.35417303442955017\n",
      "iteration 287: loss training = 0.2434223464557103, best validation = 0.35417303442955017\n",
      "iteration 288: loss training = 0.24498026924473898, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 291/300 [00:21<00:00, 14.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 289: loss training = 0.2427671871015004, best validation = 0.35417303442955017\n",
      "iteration 290: loss training = 0.24258363246917725, best validation = 0.35417303442955017\n",
      "iteration 291: loss training = 0.24063085232462203, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 295/300 [00:22<00:00, 14.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 292: loss training = 0.24055397297654832, best validation = 0.35417303442955017\n",
      "iteration 293: loss training = 0.24280444639069693, best validation = 0.35417303442955017\n",
      "iteration 294: loss training = 0.24409947225025722, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 297/300 [00:22<00:00, 14.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 295: loss training = 0.23879883331911905, best validation = 0.35417303442955017\n",
      "iteration 296: loss training = 0.24276375344821385, best validation = 0.35417303442955017\n",
      "iteration 297: loss training = 0.2416656400476183, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:22<00:00, 13.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 298: loss training = 0.24763785941260202, best validation = 0.35417303442955017\n",
      "iteration 299: loss training = 0.24091179243155889, best validation = 0.35417303442955017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.5786921509674617,\n",
       "  0.484046003648213,\n",
       "  0.46416995355061125,\n",
       "  0.4568688826901572,\n",
       "  0.44939009632383076,\n",
       "  0.4476754197052547,\n",
       "  0.4390663078853062,\n",
       "  0.43209204929215567,\n",
       "  0.4228315608842032,\n",
       "  0.4248017540999821,\n",
       "  0.41583159991673063,\n",
       "  0.4045722016266414,\n",
       "  0.3977302185126713,\n",
       "  0.39241647720336914,\n",
       "  0.39037668279239107,\n",
       "  0.3809290698596409,\n",
       "  0.37837121742112295,\n",
       "  0.3807571700641087,\n",
       "  0.3756543695926666,\n",
       "  0.3710239657333919,\n",
       "  0.36609817828450886,\n",
       "  0.3585974190916334,\n",
       "  0.3608521819114685,\n",
       "  0.3553098014422825,\n",
       "  0.3530949737344469,\n",
       "  0.34860189471926006,\n",
       "  0.33939699615750996,\n",
       "  0.33689941678728375,\n",
       "  0.33114759411130634,\n",
       "  0.32397336193493437,\n",
       "  0.31809395125934053,\n",
       "  0.3179848577295031,\n",
       "  0.311565637588501,\n",
       "  0.30786574312618803,\n",
       "  0.3008561304637364,\n",
       "  0.29815233179501127,\n",
       "  0.299314626625606,\n",
       "  0.2938208452292851,\n",
       "  0.2952635245663779,\n",
       "  0.28884997963905334,\n",
       "  0.2877547357763563,\n",
       "  0.28900828106062754,\n",
       "  0.2836122385093144,\n",
       "  0.2852025202342442,\n",
       "  0.2802932560443878,\n",
       "  0.28181768315179007,\n",
       "  0.2773824632167816,\n",
       "  0.2798006364277431,\n",
       "  0.27944043278694153,\n",
       "  0.27547845244407654,\n",
       "  0.2754521838256291,\n",
       "  0.27329947693007334,\n",
       "  0.27356700386319843,\n",
       "  0.2696948860372816,\n",
       "  0.2714280443532126,\n",
       "  0.268357800585883,\n",
       "  0.2634892932006291,\n",
       "  0.2633422932454518,\n",
       "  0.2606639266014099,\n",
       "  0.26362953441483633,\n",
       "  0.2580160456044333,\n",
       "  0.25884406907217844,\n",
       "  0.25597246416977476,\n",
       "  0.2510047512395041,\n",
       "  0.25316262032304493,\n",
       "  0.2533787808247975,\n",
       "  0.25354281280721935,\n",
       "  0.25414349351610455,\n",
       "  0.25438450276851654,\n",
       "  0.25109609748635975,\n",
       "  0.250957082424845,\n",
       "  0.2504887453147343,\n",
       "  0.25469658630234854,\n",
       "  0.24856305973870413,\n",
       "  0.25125862870897564,\n",
       "  0.2462983216558184,\n",
       "  0.24977568217686244,\n",
       "  0.2521988387618746,\n",
       "  0.24639674169676645,\n",
       "  0.24825769449983323,\n",
       "  0.24740866252354213,\n",
       "  0.247196369937488,\n",
       "  0.24898915418556758,\n",
       "  0.24540838173457555,\n",
       "  0.24786484241485596,\n",
       "  0.24645101172583445,\n",
       "  0.24735606355326517,\n",
       "  0.2496219745704106,\n",
       "  0.2440671239580427,\n",
       "  0.24059447859014785,\n",
       "  0.24766665484224046,\n",
       "  0.24452921748161316,\n",
       "  0.2439156493970326,\n",
       "  0.24686286066259658,\n",
       "  0.2437193649155753,\n",
       "  0.24604808858462743,\n",
       "  0.2444752539907183,\n",
       "  0.2448377481528691,\n",
       "  0.2463109110082899,\n",
       "  0.24444799338068282,\n",
       "  0.24495196768215724,\n",
       "  0.2463120094367436,\n",
       "  0.24182863320623124,\n",
       "  0.24494908537183488,\n",
       "  0.2390668307031904,\n",
       "  0.24368764460086823,\n",
       "  0.24491457853998458,\n",
       "  0.24383927030222757,\n",
       "  0.24496743083000183,\n",
       "  0.24332856493336813,\n",
       "  0.24076307671410696,\n",
       "  0.24505473460469926,\n",
       "  0.24571619502135686,\n",
       "  0.24128887057304382,\n",
       "  0.2405732465641839,\n",
       "  0.243964712534632,\n",
       "  0.24135310522147588,\n",
       "  0.24333550248827254,\n",
       "  0.2440745426075799,\n",
       "  0.23903813106673105,\n",
       "  0.24198604268687113,\n",
       "  0.24254094915730612,\n",
       "  0.24420349725655147,\n",
       "  0.24278736965996878,\n",
       "  0.2426197294678007,\n",
       "  0.23986711246626718,\n",
       "  0.24113651471478598,\n",
       "  0.24241894483566284,\n",
       "  0.2429089035306658,\n",
       "  0.23979235759803227,\n",
       "  0.24355068164212362,\n",
       "  0.24206484428473882,\n",
       "  0.24494674163205282,\n",
       "  0.24463031334536417,\n",
       "  0.2408211933715003,\n",
       "  0.243179623569761,\n",
       "  0.23937798823629106,\n",
       "  0.24350486482892716,\n",
       "  0.24241243728569575,\n",
       "  0.23796432146004268,\n",
       "  0.2401180522782462,\n",
       "  0.2464589583022254,\n",
       "  0.2408749567610877,\n",
       "  0.24285615342003958,\n",
       "  0.2418885337454932,\n",
       "  0.24293245588030135,\n",
       "  0.24337897981916154,\n",
       "  0.24080772485051835,\n",
       "  0.24418306350708008,\n",
       "  0.24516324060303823,\n",
       "  0.24277792232377188,\n",
       "  0.24259380783353532,\n",
       "  0.2426156039748873,\n",
       "  0.24238889345100947,\n",
       "  0.2398394857134138,\n",
       "  0.2440251729318074,\n",
       "  0.24520444657121385,\n",
       "  0.24374531848090036,\n",
       "  0.2403490607227598,\n",
       "  0.2438029944896698,\n",
       "  0.2443620881864003,\n",
       "  0.24276521801948547,\n",
       "  0.23820913689477102,\n",
       "  0.23899577132293157,\n",
       "  0.24428534294877732,\n",
       "  0.2410211775984083,\n",
       "  0.2446452613387789,\n",
       "  0.24307925360543386,\n",
       "  0.24135031870433263,\n",
       "  0.24181828115667617,\n",
       "  0.2441547725881849,\n",
       "  0.23888379335403442,\n",
       "  0.24111150630882808,\n",
       "  0.24210187579904283,\n",
       "  0.24372550419398717,\n",
       "  0.24066880345344543,\n",
       "  0.24225584736892156,\n",
       "  0.24545957786696299,\n",
       "  0.2429139635392598,\n",
       "  0.24348980614117213,\n",
       "  0.24180151522159576,\n",
       "  0.24631166883877345,\n",
       "  0.23920503684452601,\n",
       "  0.24392791731016977,\n",
       "  0.2419579667704446,\n",
       "  0.2406055416379656,\n",
       "  0.24543100808347976,\n",
       "  0.24294439171041762,\n",
       "  0.24582799204758235,\n",
       "  0.2459432887179511,\n",
       "  0.23908530601433345,\n",
       "  0.24230948729174479,\n",
       "  0.2433943258864539,\n",
       "  0.24081391521862575,\n",
       "  0.2424578879560743,\n",
       "  0.24077716682638442,\n",
       "  0.2415487744978496,\n",
       "  0.24329119707856858,\n",
       "  0.2458907493523189,\n",
       "  0.2422412782907486,\n",
       "  0.24302851302283152,\n",
       "  0.24249033417020524,\n",
       "  0.23990746481078012,\n",
       "  0.24495033281190054,\n",
       "  0.2425564421074731,\n",
       "  0.2397321547780718,\n",
       "  0.2427806258201599,\n",
       "  0.24084995687007904,\n",
       "  0.2418642512389592,\n",
       "  0.2452373547213418,\n",
       "  0.24131491567407334,\n",
       "  0.23951231156076705,\n",
       "  0.241177179983684,\n",
       "  0.2394068113395146,\n",
       "  0.2472900194781167,\n",
       "  0.24177715182304382,\n",
       "  0.24326533717768534,\n",
       "  0.24207924093518937,\n",
       "  0.24297640579087393,\n",
       "  0.24215704841273172,\n",
       "  0.2446699163743428,\n",
       "  0.24128037691116333,\n",
       "  0.24073905604226248,\n",
       "  0.24048153843198503,\n",
       "  0.24302210765225546,\n",
       "  0.23963714497429983,\n",
       "  0.23933605423995427,\n",
       "  0.24194809794425964,\n",
       "  0.24282638728618622,\n",
       "  0.24390420743397304,\n",
       "  0.2375799013035638,\n",
       "  0.24301469326019287,\n",
       "  0.24443620443344116,\n",
       "  0.2384371885231563,\n",
       "  0.24420879568372453,\n",
       "  0.2404014446905681,\n",
       "  0.24262447016579763,\n",
       "  0.24202505392687662,\n",
       "  0.24231754669121333,\n",
       "  0.2430682203599385,\n",
       "  0.24219404586723872,\n",
       "  0.24459911670003617,\n",
       "  0.24434072630746023,\n",
       "  0.2415639055626733,\n",
       "  0.24622502710138047,\n",
       "  0.24629473686218262,\n",
       "  0.23782590883118765,\n",
       "  0.2432441200528826,\n",
       "  0.2411154167992728,\n",
       "  0.24223043876034872,\n",
       "  0.24521845153399877,\n",
       "  0.24054054915905,\n",
       "  0.24203835427761078,\n",
       "  0.24250281495707376,\n",
       "  0.2391452874456133,\n",
       "  0.24298048870904104,\n",
       "  0.24345918212618148,\n",
       "  0.24462912338120596,\n",
       "  0.24467098074299948,\n",
       "  0.24202624814850943,\n",
       "  0.2417021244764328,\n",
       "  0.23982195556163788,\n",
       "  0.23935229863439286,\n",
       "  0.24134006244795664,\n",
       "  0.24298536351748876,\n",
       "  0.2431649544409343,\n",
       "  0.2410425501210349,\n",
       "  0.2440860186304365,\n",
       "  0.24391135573387146,\n",
       "  0.241349458694458,\n",
       "  0.24337645513670786,\n",
       "  0.24404311605862208,\n",
       "  0.2413125272308077,\n",
       "  0.24003250684056962,\n",
       "  0.2396454576935087,\n",
       "  0.2423561406987054,\n",
       "  0.24468196077006205,\n",
       "  0.24202714647565568,\n",
       "  0.24100572296551295,\n",
       "  0.2420818316084998,\n",
       "  0.24047742571149552,\n",
       "  0.24192206774439132,\n",
       "  0.2423317496265684,\n",
       "  0.2468894783939634,\n",
       "  0.24669270856039865,\n",
       "  0.24197267421654292,\n",
       "  0.24074981255190714,\n",
       "  0.2434223464557103,\n",
       "  0.24498026924473898,\n",
       "  0.2427671871015004,\n",
       "  0.24258363246917725,\n",
       "  0.24063085232462203,\n",
       "  0.24055397297654832,\n",
       "  0.24280444639069693,\n",
       "  0.24409947225025722,\n",
       "  0.23879883331911905,\n",
       "  0.24276375344821385,\n",
       "  0.2416656400476183,\n",
       "  0.24763785941260202,\n",
       "  0.24091179243155889],\n",
       " [0.4752357304096222,\n",
       "  0.45049795508384705,\n",
       "  0.4428417682647705,\n",
       "  0.4436868727207184,\n",
       "  0.45081713795661926,\n",
       "  0.4424890726804733,\n",
       "  0.44052062928676605,\n",
       "  0.4422299265861511,\n",
       "  0.4380560368299484,\n",
       "  0.4333367496728897,\n",
       "  0.4317473918199539,\n",
       "  0.4193747192621231,\n",
       "  0.41545331478118896,\n",
       "  0.41633957624435425,\n",
       "  0.40886878967285156,\n",
       "  0.40738777816295624,\n",
       "  0.4062587767839432,\n",
       "  0.40391457080841064,\n",
       "  0.4017571806907654,\n",
       "  0.3985210955142975,\n",
       "  0.40108785033226013,\n",
       "  0.40108901262283325,\n",
       "  0.3966952860355377,\n",
       "  0.39800164103507996,\n",
       "  0.3926200568675995,\n",
       "  0.3893306851387024,\n",
       "  0.3857140392065048,\n",
       "  0.3783581107854843,\n",
       "  0.3708801120519638,\n",
       "  0.3689565658569336,\n",
       "  0.36340469121932983,\n",
       "  0.36038585007190704,\n",
       "  0.35974903404712677,\n",
       "  0.35831277072429657,\n",
       "  0.35822683572769165,\n",
       "  0.3586067408323288,\n",
       "  0.35745929181575775,\n",
       "  0.3572627902030945,\n",
       "  0.356000691652298,\n",
       "  0.35700613260269165,\n",
       "  0.35585354268550873,\n",
       "  0.3566368371248245,\n",
       "  0.35802023112773895,\n",
       "  0.35625092685222626,\n",
       "  0.3578404039144516,\n",
       "  0.3563429117202759,\n",
       "  0.3558243364095688,\n",
       "  0.3543839603662491,\n",
       "  0.35595282912254333,\n",
       "  0.35698162019252777,\n",
       "  0.36009781062602997,\n",
       "  0.3573228418827057,\n",
       "  0.35783539712429047,\n",
       "  0.3549540787935257,\n",
       "  0.3562087267637253,\n",
       "  0.35417303442955017,\n",
       "  0.3552194833755493,\n",
       "  0.35719262063503265,\n",
       "  0.35928504168987274,\n",
       "  0.35800595581531525,\n",
       "  0.3569534122943878,\n",
       "  0.3569571226835251,\n",
       "  0.3582351803779602,\n",
       "  0.35675251483917236,\n",
       "  0.3567124605178833,\n",
       "  0.35715727508068085,\n",
       "  0.35754410922527313,\n",
       "  0.3590199649333954,\n",
       "  0.35794585943222046,\n",
       "  0.35870327055454254,\n",
       "  0.3576063960790634,\n",
       "  0.3576623648405075,\n",
       "  0.3580302745103836,\n",
       "  0.3575940430164337,\n",
       "  0.35761627554893494,\n",
       "  0.3570322245359421,\n",
       "  0.3568289130926132,\n",
       "  0.35563692450523376,\n",
       "  0.35565145313739777,\n",
       "  0.35569556057453156,\n",
       "  0.35671643912792206,\n",
       "  0.3571428060531616,\n",
       "  0.35772010684013367,\n",
       "  0.35745151340961456,\n",
       "  0.3580053448677063,\n",
       "  0.35796648263931274,\n",
       "  0.3576621264219284,\n",
       "  0.35691145062446594,\n",
       "  0.35710787773132324,\n",
       "  0.35719045996665955,\n",
       "  0.35718613862991333,\n",
       "  0.35717928409576416,\n",
       "  0.35725921392440796,\n",
       "  0.35711945593357086,\n",
       "  0.3566868305206299,\n",
       "  0.35665713250637054,\n",
       "  0.3567679822444916,\n",
       "  0.35691608488559723,\n",
       "  0.35717563331127167,\n",
       "  0.3570545166730881,\n",
       "  0.35718758404254913,\n",
       "  0.3571752458810806,\n",
       "  0.35678860545158386,\n",
       "  0.35655204951763153,\n",
       "  0.35664328932762146,\n",
       "  0.35670463740825653,\n",
       "  0.3570229262113571,\n",
       "  0.35740529000759125,\n",
       "  0.35740306973457336,\n",
       "  0.3573191910982132,\n",
       "  0.35768042504787445,\n",
       "  0.3572096526622772,\n",
       "  0.3574225604534149,\n",
       "  0.3568946123123169,\n",
       "  0.35773538053035736,\n",
       "  0.357772096991539,\n",
       "  0.3573434501886368,\n",
       "  0.3574844151735306,\n",
       "  0.3575737774372101,\n",
       "  0.357466459274292,\n",
       "  0.3572964519262314,\n",
       "  0.35637369751930237,\n",
       "  0.35642579197883606,\n",
       "  0.35645692050457,\n",
       "  0.3566223829984665,\n",
       "  0.3565967530012131,\n",
       "  0.3565964847803116,\n",
       "  0.35652677714824677,\n",
       "  0.3565330505371094,\n",
       "  0.3565223515033722,\n",
       "  0.3565104603767395,\n",
       "  0.3565275967121124,\n",
       "  0.3565439134836197,\n",
       "  0.3573824018239975,\n",
       "  0.3573848307132721,\n",
       "  0.35736899077892303,\n",
       "  0.3573339730501175,\n",
       "  0.3564905524253845,\n",
       "  0.35648053884506226,\n",
       "  0.3564823120832443,\n",
       "  0.35650651156902313,\n",
       "  0.3565259426832199,\n",
       "  0.3568408191204071,\n",
       "  0.3568226248025894,\n",
       "  0.356823205947876,\n",
       "  0.35653290152549744,\n",
       "  0.3565477877855301,\n",
       "  0.35656625032424927,\n",
       "  0.3565763682126999,\n",
       "  0.3565705269575119,\n",
       "  0.3565671592950821,\n",
       "  0.3565604239702225,\n",
       "  0.3565545380115509,\n",
       "  0.356548935174942,\n",
       "  0.3565433770418167,\n",
       "  0.3565385788679123,\n",
       "  0.35653825104236603,\n",
       "  0.35653750598430634,\n",
       "  0.35653194785118103,\n",
       "  0.35652707517147064,\n",
       "  0.35652486979961395,\n",
       "  0.3565251976251602,\n",
       "  0.3565244525671005,\n",
       "  0.3563071936368942,\n",
       "  0.356305867433548,\n",
       "  0.35630348324775696,\n",
       "  0.35629764199256897,\n",
       "  0.3562946170568466,\n",
       "  0.3562953770160675,\n",
       "  0.3562951982021332,\n",
       "  0.3562929481267929,\n",
       "  0.35629646480083466,\n",
       "  0.35630491375923157,\n",
       "  0.3563069552183151,\n",
       "  0.35631176829338074,\n",
       "  0.35632121562957764,\n",
       "  0.35633550584316254,\n",
       "  0.35635043680667877,\n",
       "  0.3563549220561981,\n",
       "  0.35635773837566376,\n",
       "  0.35635723173618317,\n",
       "  0.3563559204339981,\n",
       "  0.3563539981842041,\n",
       "  0.3563513457775116,\n",
       "  0.3563487231731415,\n",
       "  0.35634665191173553,\n",
       "  0.3563447743654251,\n",
       "  0.3563438206911087,\n",
       "  0.3563418537378311,\n",
       "  0.3563401997089386,\n",
       "  0.35633909702301025,\n",
       "  0.3563372939825058,\n",
       "  0.3563355803489685,\n",
       "  0.35633453726768494,\n",
       "  0.35633261501789093,\n",
       "  0.35633163154125214,\n",
       "  0.3563314527273178,\n",
       "  0.3563312143087387,\n",
       "  0.356330931186676,\n",
       "  0.3563302159309387,\n",
       "  0.3563287556171417,\n",
       "  0.3563280552625656,\n",
       "  0.3563266396522522,\n",
       "  0.356324702501297,\n",
       "  0.35632333159446716,\n",
       "  0.35632196068763733,\n",
       "  0.3563206344842911,\n",
       "  0.3563195466995239,\n",
       "  0.3563201576471329,\n",
       "  0.3563191592693329,\n",
       "  0.3563190996646881,\n",
       "  0.35631905496120453,\n",
       "  0.35631895065307617,\n",
       "  0.3563189059495926,\n",
       "  0.35631875693798065,\n",
       "  0.3563185781240463,\n",
       "  0.35631848871707916,\n",
       "  0.3563183695077896,\n",
       "  0.3563183695077896,\n",
       "  0.35631832480430603,\n",
       "  0.3563181459903717,\n",
       "  0.35631802678108215,\n",
       "  0.35631775856018066,\n",
       "  0.3563176542520523,\n",
       "  0.3563176244497299,\n",
       "  0.3563176095485687,\n",
       "  0.3563174307346344,\n",
       "  0.3563173860311508,\n",
       "  0.3563171327114105,\n",
       "  0.3563168793916702,\n",
       "  0.3563168793916702,\n",
       "  0.3563169538974762,\n",
       "  0.35631704330444336,\n",
       "  0.3563171774148941,\n",
       "  0.3563174605369568,\n",
       "  0.3563176244497299,\n",
       "  0.356317475438118,\n",
       "  0.3563173860311508,\n",
       "  0.3563172072172165,\n",
       "  0.35631701350212097,\n",
       "  0.35631702840328217,\n",
       "  0.35631704330444336,\n",
       "  0.35631705820560455,\n",
       "  0.35631708800792694,\n",
       "  0.35631708800792694,\n",
       "  0.35631702840328217,\n",
       "  0.35631702840328217,\n",
       "  0.3563169986009598,\n",
       "  0.3563169986009598,\n",
       "  0.35631702840328217,\n",
       "  0.35631704330444336,\n",
       "  0.35631705820560455,\n",
       "  0.35631708800792694,\n",
       "  0.3563171923160553,\n",
       "  0.3563172370195389,\n",
       "  0.3563172221183777,\n",
       "  0.3563171923160553,\n",
       "  0.3563172072172165,\n",
       "  0.3563172519207001,\n",
       "  0.35631728172302246,\n",
       "  0.35631726682186127,\n",
       "  0.35631729662418365,\n",
       "  0.35631732642650604,\n",
       "  0.35631729662418365,\n",
       "  0.35631726682186127,\n",
       "  0.35631726682186127,\n",
       "  0.3563172519207001,\n",
       "  0.35631728172302246,\n",
       "  0.35631726682186127,\n",
       "  0.35631726682186127,\n",
       "  0.3563172370195389,\n",
       "  0.3563172072172165,\n",
       "  0.3563172519207001,\n",
       "  0.35631726682186127,\n",
       "  0.35631726682186127,\n",
       "  0.35631726682186127,\n",
       "  0.35631726682186127,\n",
       "  0.35631726682186127,\n",
       "  0.3563172370195389,\n",
       "  0.3563172519207001,\n",
       "  0.3563172519207001,\n",
       "  0.3563172370195389,\n",
       "  0.3563172221183777,\n",
       "  0.3563172370195389,\n",
       "  0.35631726682186127,\n",
       "  0.3563172370195389,\n",
       "  0.3563172370195389,\n",
       "  0.3563172519207001,\n",
       "  0.3563172519207001,\n",
       "  0.3563171923160553,\n",
       "  0.3563172519207001,\n",
       "  0.3563172370195389,\n",
       "  0.35631726682186127,\n",
       "  0.3563172370195389,\n",
       "  0.35631726682186127,\n",
       "  0.3563172370195389,\n",
       "  0.35631726682186127,\n",
       "  0.3563172370195389,\n",
       "  0.3563172370195389,\n",
       "  0.3563172370195389])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da_music = DA_MUSIC(m, d, array, dev)\n",
    "train(da_music, nbEpoches, lr, wd, train_loader, valid_loader, path+'da_music_'+str(snr)+'dB_ula.pth', train_func, valid_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0: loss training = 0.5710758141108921, best validation = 0.46782033145427704\n",
      "iteration 1: loss training = 0.4712116888591221, best validation = 0.46782033145427704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/300 [00:00<00:12, 23.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 2: loss training = 0.46353458932467867, best validation = 0.46782033145427704\n",
      "iteration 3: loss training = 0.46095746755599976, best validation = 0.4661186933517456\n",
      "iteration 4: loss training = 0.44955901162964956, best validation = 0.4460771530866623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 6/300 [00:00<00:12, 23.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 5: loss training = 0.4356955034392221, best validation = 0.42884834110736847\n",
      "iteration 6: loss training = 0.4177102063383375, best validation = 0.4164275825023651\n",
      "iteration 7: loss training = 0.40321077193532673, best validation = 0.41249722242355347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 9/300 [00:00<00:15, 18.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 8: loss training = 0.39312704120363506, best validation = 0.40606047213077545\n",
      "iteration 9: loss training = 0.3884443938732147, best validation = 0.40606047213077545\n",
      "iteration 10: loss training = 0.38553630879947115, best validation = 0.40336865186691284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 12/300 [00:00<00:14, 19.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 11: loss training = 0.38611820340156555, best validation = 0.4010127931833267\n",
      "iteration 12: loss training = 0.38412231632641386, best validation = 0.3971506804227829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 15/300 [00:00<00:13, 20.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 13: loss training = 0.373800699199949, best validation = 0.39042073488235474\n",
      "iteration 14: loss training = 0.3696348028523581, best validation = 0.39042073488235474\n",
      "iteration 15: loss training = 0.36573647601263864, best validation = 0.385025218129158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 18/300 [00:00<00:12, 21.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 16: loss training = 0.3588628428322928, best validation = 0.37786000967025757\n",
      "iteration 17: loss training = 0.35319691044943674, best validation = 0.36761675775051117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 21/300 [00:00<00:12, 23.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 18: loss training = 0.34178524783679415, best validation = 0.3577103912830353\n",
      "iteration 19: loss training = 0.32510347025735037, best validation = 0.3476676642894745\n",
      "iteration 20: loss training = 0.32487425208091736, best validation = 0.3476676642894745\n",
      "iteration 21: loss training = 0.3261845963341849, best validation = 0.3476676642894745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 24/300 [00:01<00:11, 23.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 22: loss training = 0.33117343698229107, best validation = 0.3462018221616745\n",
      "iteration 23: loss training = 0.30628874472209383, best validation = 0.32128243148326874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 27/300 [00:01<00:11, 24.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 24: loss training = 0.29456324662481037, best validation = 0.31986190378665924\n",
      "iteration 25: loss training = 0.3101255084787096, best validation = 0.31986190378665924\n",
      "iteration 26: loss training = 0.3078127545969827, best validation = 0.31986190378665924\n",
      "iteration 27: loss training = 0.29549034578459604, best validation = 0.31753070652484894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 30/300 [00:01<00:11, 24.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 28: loss training = 0.285651649747576, best validation = 0.3064710944890976\n",
      "iteration 29: loss training = 0.27724653482437134, best validation = 0.303581178188324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 33/300 [00:01<00:10, 24.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 30: loss training = 0.27418103388377596, best validation = 0.2992022782564163\n",
      "iteration 31: loss training = 0.26983845233917236, best validation = 0.2980645149946213\n",
      "iteration 32: loss training = 0.27041477390698027, best validation = 0.2939324527978897\n",
      "iteration 33: loss training = 0.26281274003641947, best validation = 0.2930019795894623\n",
      "iteration 34: loss training = 0.2606731951236725, best validation = 0.2898593693971634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 36/300 [00:01<00:10, 24.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 35: loss training = 0.26247202285698484, best validation = 0.28758497536182404\n",
      "iteration 36: loss training = 0.2599143513611385, best validation = 0.28758497536182404\n",
      "iteration 37: loss training = 0.26351400571210043, best validation = 0.28758497536182404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 39/300 [00:01<00:10, 24.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 38: loss training = 0.2585378757544926, best validation = 0.28494445979595184\n",
      "iteration 39: loss training = 0.2565519000802721, best validation = 0.28472496569156647\n",
      "iteration 40: loss training = 0.2558941330228533, best validation = 0.283376082777977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 42/300 [00:01<00:10, 25.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 41: loss training = 0.2539624571800232, best validation = 0.28200414776802063\n",
      "iteration 42: loss training = 0.2514021566935948, best validation = 0.28200414776802063\n",
      "iteration 43: loss training = 0.2561993492501123, best validation = 0.28200414776802063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 45/300 [00:01<00:09, 25.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 44: loss training = 0.2528613976069859, best validation = 0.28200414776802063\n",
      "iteration 45: loss training = 0.25185068590300425, best validation = 0.2807650715112686\n",
      "iteration 46: loss training = 0.25168876349925995, best validation = 0.2789170444011688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 48/300 [00:02<00:09, 25.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 47: loss training = 0.2454661407641002, best validation = 0.2789170444011688\n",
      "iteration 48: loss training = 0.24787018980298722, best validation = 0.27823740243911743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 51/300 [00:02<00:09, 24.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 49: loss training = 0.2467388255255563, best validation = 0.27823740243911743\n",
      "iteration 50: loss training = 0.24751755169459752, best validation = 0.2779146581888199\n",
      "iteration 51: loss training = 0.2467898109129497, best validation = 0.2761964052915573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 54/300 [00:02<00:09, 24.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 52: loss training = 0.24578942784241267, best validation = 0.2761964052915573\n",
      "iteration 53: loss training = 0.24613348501069204, best validation = 0.2761964052915573\n",
      "iteration 54: loss training = 0.24286408722400665, best validation = 0.27589279413223267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 57/300 [00:02<00:09, 24.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 55: loss training = 0.24005939066410065, best validation = 0.27589279413223267\n",
      "iteration 56: loss training = 0.2394827284983226, best validation = 0.27378931641578674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 60/300 [00:02<00:09, 24.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 57: loss training = 0.24131291678973607, best validation = 0.27016590535640717\n",
      "iteration 58: loss training = 0.23884436701025283, best validation = 0.27016590535640717\n",
      "iteration 59: loss training = 0.23931648901530675, best validation = 0.27016590535640717\n",
      "iteration 60: loss training = 0.2343248724937439, best validation = 0.27016590535640717\n",
      "iteration 61: loss training = 0.23386596143245697, best validation = 0.27016590535640717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 66/300 [00:02<00:09, 23.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 62: loss training = 0.23264212693486894, best validation = 0.27016590535640717\n",
      "iteration 63: loss training = 0.23441165259906224, best validation = 0.2699168026447296\n",
      "iteration 64: loss training = 0.23808575102261134, best validation = 0.2699168026447296\n",
      "iteration 65: loss training = 0.23338858144623892, best validation = 0.26975786685943604\n",
      "iteration 66: loss training = 0.23051381749766214, best validation = 0.26975786685943604\n",
      "iteration 67: loss training = 0.23337663922991073, best validation = 0.26975786685943604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 72/300 [00:03<00:09, 25.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 68: loss training = 0.23484161921909877, best validation = 0.2695755064487457\n",
      "iteration 69: loss training = 0.23376749455928802, best validation = 0.2689654380083084\n",
      "iteration 70: loss training = 0.23268612793513707, best validation = 0.2689654380083084\n",
      "iteration 71: loss training = 0.23337217952523912, best validation = 0.2689654380083084\n",
      "iteration 72: loss training = 0.231155093227114, best validation = 0.2689654380083084\n",
      "iteration 73: loss training = 0.23082431512219564, best validation = 0.26878775656223297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 75/300 [00:03<00:08, 25.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 74: loss training = 0.23110992355006083, best validation = 0.26878775656223297\n",
      "iteration 75: loss training = 0.23093762355191366, best validation = 0.2687039226293564\n",
      "iteration 76: loss training = 0.23287890000002726, best validation = 0.26853545010089874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 78/300 [00:03<00:08, 24.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 77: loss training = 0.22951711501393998, best validation = 0.2683413028717041\n",
      "iteration 78: loss training = 0.22879086009093694, best validation = 0.2683413028717041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 81/300 [00:03<00:08, 24.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 79: loss training = 0.22977187590939657, best validation = 0.26832590997219086\n",
      "iteration 80: loss training = 0.22943588026932307, best validation = 0.26800772547721863\n",
      "iteration 81: loss training = 0.2301454586642129, best validation = 0.26785340905189514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 84/300 [00:03<00:09, 23.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 82: loss training = 0.22957350313663483, best validation = 0.26757414638996124\n",
      "iteration 83: loss training = 0.23026608995028905, best validation = 0.26757414638996124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 87/300 [00:03<00:08, 24.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 84: loss training = 0.2344042956829071, best validation = 0.26757414638996124\n",
      "iteration 85: loss training = 0.2296550486768995, best validation = 0.2669088989496231\n",
      "iteration 86: loss training = 0.2314765921660832, best validation = 0.26667971909046173\n",
      "iteration 87: loss training = 0.22989534054483687, best validation = 0.2665656805038452\n",
      "iteration 88: loss training = 0.2374074012041092, best validation = 0.2664273679256439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 93/300 [00:03<00:08, 24.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 89: loss training = 0.22931704776627676, best validation = 0.2664273679256439\n",
      "iteration 90: loss training = 0.22635370918682643, best validation = 0.2664273679256439\n",
      "iteration 91: loss training = 0.23284460391317094, best validation = 0.2664273679256439\n",
      "iteration 92: loss training = 0.2272774875164032, best validation = 0.2664273679256439\n",
      "iteration 93: loss training = 0.22935215064457484, best validation = 0.26642362773418427\n",
      "iteration 94: loss training = 0.2259791237967355, best validation = 0.26642362773418427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 99/300 [00:04<00:07, 26.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 95: loss training = 0.2299734013421195, best validation = 0.2664235085248947\n",
      "iteration 96: loss training = 0.22738205109323775, best validation = 0.26639822125434875\n",
      "iteration 97: loss training = 0.22970502717154367, best validation = 0.26639503240585327\n",
      "iteration 98: loss training = 0.22655547729560307, best validation = 0.2663690000772476\n",
      "iteration 99: loss training = 0.22765967462744033, best validation = 0.26636604964733124\n",
      "iteration 100: loss training = 0.2301414225782667, best validation = 0.2662985920906067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 105/300 [00:04<00:07, 27.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 101: loss training = 0.22752676904201508, best validation = 0.26624172925949097\n",
      "iteration 102: loss training = 0.22911103708403452, best validation = 0.26624172925949097\n",
      "iteration 103: loss training = 0.22772190187658584, best validation = 0.26624172925949097\n",
      "iteration 104: loss training = 0.23102188748972757, best validation = 0.26624172925949097\n",
      "iteration 105: loss training = 0.22760935127735138, best validation = 0.26624172925949097\n",
      "iteration 106: loss training = 0.23079029789992742, best validation = 0.2662365436553955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 111/300 [00:04<00:06, 27.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 107: loss training = 0.2286376655101776, best validation = 0.2662125825881958\n",
      "iteration 108: loss training = 0.2235229845557894, best validation = 0.2660883963108063\n",
      "iteration 109: loss training = 0.23086610436439514, best validation = 0.2660040110349655\n",
      "iteration 110: loss training = 0.227517836860248, best validation = 0.26598140597343445\n",
      "iteration 111: loss training = 0.23184712656906672, best validation = 0.2658986747264862\n",
      "iteration 112: loss training = 0.2263682974236352, best validation = 0.26585492491722107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 117/300 [00:04<00:06, 27.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 113: loss training = 0.22990090080669948, best validation = 0.26525233685970306\n",
      "iteration 114: loss training = 0.22849901233400619, best validation = 0.2651941329240799\n",
      "iteration 115: loss training = 0.22914542044912065, best validation = 0.2651941329240799\n",
      "iteration 116: loss training = 0.2276364756481988, best validation = 0.2651941329240799\n",
      "iteration 117: loss training = 0.2263272830418178, best validation = 0.2651941329240799\n",
      "iteration 118: loss training = 0.22761552461556026, best validation = 0.2651941329240799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 123/300 [00:04<00:06, 28.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 119: loss training = 0.22880564630031586, best validation = 0.2651941329240799\n",
      "iteration 120: loss training = 0.2290617333991187, best validation = 0.2651941329240799\n",
      "iteration 121: loss training = 0.22653334055628097, best validation = 0.2651941329240799\n",
      "iteration 122: loss training = 0.2264995915549142, best validation = 0.2651941329240799\n",
      "iteration 123: loss training = 0.22643260870661056, best validation = 0.2651941329240799\n",
      "iteration 124: loss training = 0.2247356538261686, best validation = 0.2651941329240799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 129/300 [00:05<00:05, 28.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 125: loss training = 0.23064994173390524, best validation = 0.2651941329240799\n",
      "iteration 126: loss training = 0.2263995579310826, best validation = 0.2651941329240799\n",
      "iteration 127: loss training = 0.22815964903150285, best validation = 0.2651941329240799\n",
      "iteration 128: loss training = 0.2282795203583581, best validation = 0.2651941329240799\n",
      "iteration 129: loss training = 0.22811057525021688, best validation = 0.2651941329240799\n",
      "iteration 130: loss training = 0.23022877744265965, best validation = 0.2651941329240799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 135/300 [00:05<00:05, 28.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 131: loss training = 0.2267958245107106, best validation = 0.2651941329240799\n",
      "iteration 132: loss training = 0.22959889258657182, best validation = 0.2651941329240799\n",
      "iteration 133: loss training = 0.22842087277344295, best validation = 0.2651941329240799\n",
      "iteration 134: loss training = 0.22845656744071416, best validation = 0.2651941329240799\n",
      "iteration 135: loss training = 0.22959514600890024, best validation = 0.2651941329240799\n",
      "iteration 136: loss training = 0.22345395173345292, best validation = 0.2651941329240799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 141/300 [00:05<00:05, 28.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 137: loss training = 0.2290991906608854, best validation = 0.2651941329240799\n",
      "iteration 138: loss training = 0.2266043871641159, best validation = 0.2651941329240799\n",
      "iteration 139: loss training = 0.22869438145841872, best validation = 0.2651941329240799\n",
      "iteration 140: loss training = 0.2251970555101122, best validation = 0.2651941329240799\n",
      "iteration 141: loss training = 0.22577767074108124, best validation = 0.2651941329240799\n",
      "iteration 142: loss training = 0.2254635351044791, best validation = 0.2651941329240799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 147/300 [00:05<00:05, 28.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 143: loss training = 0.22687010041304997, best validation = 0.2651941329240799\n",
      "iteration 144: loss training = 0.2263164988585881, best validation = 0.2651941329240799\n",
      "iteration 145: loss training = 0.225773030093738, best validation = 0.2651941329240799\n",
      "iteration 146: loss training = 0.2265675323350089, best validation = 0.2651941329240799\n",
      "iteration 147: loss training = 0.22617631937776292, best validation = 0.2651941329240799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 150/300 [00:05<00:06, 23.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 148: loss training = 0.22234334903103964, best validation = 0.2651941329240799\n",
      "iteration 149: loss training = 0.23013016368661607, best validation = 0.2651941329240799\n",
      "iteration 150: loss training = 0.2252974041870662, best validation = 0.2651941329240799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 153/300 [00:06<00:05, 24.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 151: loss training = 0.22426737632070268, best validation = 0.2651941329240799\n",
      "iteration 152: loss training = 0.22678320109844208, best validation = 0.2651941329240799\n",
      "iteration 153: loss training = 0.22354229433195932, best validation = 0.2651941329240799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 156/300 [00:06<00:05, 25.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 154: loss training = 0.2298459048782076, best validation = 0.2651941329240799\n",
      "iteration 155: loss training = 0.230593347123691, best validation = 0.2651941329240799\n",
      "iteration 156: loss training = 0.22450202916349685, best validation = 0.2651941329240799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 159/300 [00:06<00:05, 25.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 157: loss training = 0.22612707316875458, best validation = 0.2651941329240799\n",
      "iteration 158: loss training = 0.22657661778586252, best validation = 0.2651941329240799\n",
      "iteration 159: loss training = 0.22755866604191916, best validation = 0.2651941329240799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 162/300 [00:06<00:05, 26.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 160: loss training = 0.22577233186789922, best validation = 0.2651941329240799\n",
      "iteration 161: loss training = 0.22634400640215194, best validation = 0.2651941329240799\n",
      "iteration 162: loss training = 0.22553481587341853, best validation = 0.2651941329240799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 165/300 [00:06<00:05, 26.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 163: loss training = 0.22507611768586294, best validation = 0.2651941329240799\n",
      "iteration 164: loss training = 0.23145777412823268, best validation = 0.2651941329240799\n",
      "iteration 165: loss training = 0.2252106751714434, best validation = 0.2651941329240799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 168/300 [00:06<00:04, 26.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 166: loss training = 0.22528674134186336, best validation = 0.2651941329240799\n",
      "iteration 167: loss training = 0.22672100152288163, best validation = 0.2651941329240799\n",
      "iteration 168: loss training = 0.22621129027434758, best validation = 0.2651941329240799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 171/300 [00:06<00:04, 26.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 169: loss training = 0.2286779454776219, best validation = 0.2651941329240799\n",
      "iteration 170: loss training = 0.22902667948177882, best validation = 0.2651941329240799\n",
      "iteration 171: loss training = 0.22922358981200627, best validation = 0.2651941329240799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 174/300 [00:06<00:04, 27.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 172: loss training = 0.22377377109868185, best validation = 0.2651941329240799\n",
      "iteration 173: loss training = 0.23185996285506658, best validation = 0.2651941329240799\n",
      "iteration 174: loss training = 0.22657614946365356, best validation = 0.2651941329240799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 177/300 [00:06<00:04, 27.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 175: loss training = 0.22616168005125864, best validation = 0.2651941329240799\n",
      "iteration 176: loss training = 0.22893187829426356, best validation = 0.2651941329240799\n",
      "iteration 177: loss training = 0.22379536500998906, best validation = 0.2651941329240799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 180/300 [00:07<00:04, 26.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 178: loss training = 0.2269598458494459, best validation = 0.2651941329240799\n",
      "iteration 179: loss training = 0.23013669678143092, best validation = 0.2651941329240799\n",
      "iteration 180: loss training = 0.22512458051953996, best validation = 0.2651941329240799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 183/300 [00:07<00:04, 26.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 181: loss training = 0.2301366925239563, best validation = 0.2651941329240799\n",
      "iteration 182: loss training = 0.22647975385189056, best validation = 0.2651941329240799\n",
      "iteration 183: loss training = 0.22989727982452937, best validation = 0.2651941329240799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 186/300 [00:07<00:04, 26.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 184: loss training = 0.22367540214742934, best validation = 0.2651941329240799\n",
      "iteration 185: loss training = 0.22756101829665049, best validation = 0.2651941329240799\n",
      "iteration 186: loss training = 0.22406438205923354, best validation = 0.2651941329240799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 189/300 [00:07<00:04, 26.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 187: loss training = 0.22744409101349966, best validation = 0.2651941329240799\n",
      "iteration 188: loss training = 0.22380575324807847, best validation = 0.2651941329240799\n",
      "iteration 189: loss training = 0.22255621637616838, best validation = 0.2651941329240799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 192/300 [00:07<00:04, 26.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 190: loss training = 0.22475468686648778, best validation = 0.2651941329240799\n",
      "iteration 191: loss training = 0.2275052453790392, best validation = 0.2651941329240799\n",
      "iteration 192: loss training = 0.2253693150622504, best validation = 0.2651941329240799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 195/300 [00:07<00:03, 26.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 193: loss training = 0.2249672327722822, best validation = 0.2651941329240799\n",
      "iteration 194: loss training = 0.2253518189702715, best validation = 0.2651941329240799\n",
      "iteration 195: loss training = 0.22736825687544687, best validation = 0.2651941329240799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 198/300 [00:07<00:03, 27.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 196: loss training = 0.22411203810146876, best validation = 0.2651941329240799\n",
      "iteration 197: loss training = 0.22637256979942322, best validation = 0.2651941329240799\n",
      "iteration 198: loss training = 0.22884372089590346, best validation = 0.2651941329240799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 201/300 [00:07<00:03, 27.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 199: loss training = 0.22724583745002747, best validation = 0.2651941329240799\n",
      "iteration 200: loss training = 0.2287029560123171, best validation = 0.2651941329240799\n",
      "iteration 201: loss training = 0.22686525966439927, best validation = 0.2651941329240799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 204/300 [00:07<00:03, 27.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 202: loss training = 0.22755352301256998, best validation = 0.2651941329240799\n",
      "iteration 203: loss training = 0.22847458294459752, best validation = 0.2651941329240799\n",
      "iteration 204: loss training = 0.22820267294134414, best validation = 0.2651941329240799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 207/300 [00:08<00:03, 27.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 205: loss training = 0.22293455473014287, best validation = 0.2651941329240799\n",
      "iteration 206: loss training = 0.22717545287949698, best validation = 0.2651941329240799\n",
      "iteration 207: loss training = 0.22863514508519853, best validation = 0.2651941329240799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 210/300 [00:08<00:03, 27.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 208: loss training = 0.22692173719406128, best validation = 0.2651941329240799\n",
      "iteration 209: loss training = 0.22841162979602814, best validation = 0.2651941329240799\n",
      "iteration 210: loss training = 0.22971912367003305, best validation = 0.2651941329240799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 213/300 [00:08<00:03, 26.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 211: loss training = 0.225399021591459, best validation = 0.2651941329240799\n",
      "iteration 212: loss training = 0.23108779532568796, best validation = 0.2651941329240799\n",
      "iteration 213: loss training = 0.22824055595057352, best validation = 0.2651941329240799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 216/300 [00:08<00:03, 27.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 214: loss training = 0.22647123890263693, best validation = 0.2651941329240799\n",
      "iteration 215: loss training = 0.22602802302156175, best validation = 0.2651941329240799\n",
      "iteration 216: loss training = 0.22643693217209407, best validation = 0.2651941329240799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 219/300 [00:08<00:02, 27.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 217: loss training = 0.2304830742733819, best validation = 0.2651941329240799\n",
      "iteration 218: loss training = 0.22720360330172948, best validation = 0.2651941329240799\n",
      "iteration 219: loss training = 0.23035561399800436, best validation = 0.2651941329240799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 222/300 [00:08<00:02, 26.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 220: loss training = 0.22869074983256205, best validation = 0.2651941329240799\n",
      "iteration 221: loss training = 0.22429836222103663, best validation = 0.2651941329240799\n",
      "iteration 222: loss training = 0.2258522765977042, best validation = 0.2651941329240799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 225/300 [00:08<00:02, 26.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 223: loss training = 0.22806079472814286, best validation = 0.2651941329240799\n",
      "iteration 224: loss training = 0.23041264287063054, best validation = 0.2651941329240799\n",
      "iteration 225: loss training = 0.22825097611972264, best validation = 0.2651941329240799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 228/300 [00:08<00:02, 27.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 226: loss training = 0.2257236476455416, best validation = 0.2651941329240799\n",
      "iteration 227: loss training = 0.22476987540721893, best validation = 0.2651941329240799\n",
      "iteration 228: loss training = 0.22596319445541926, best validation = 0.2651941329240799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 231/300 [00:08<00:02, 27.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 229: loss training = 0.22688798606395721, best validation = 0.2651941329240799\n",
      "iteration 230: loss training = 0.2293681161744254, best validation = 0.2651941329240799\n",
      "iteration 231: loss training = 0.22865883367402212, best validation = 0.2651941329240799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 234/300 [00:09<00:02, 27.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 232: loss training = 0.2272825837135315, best validation = 0.2651941329240799\n",
      "iteration 233: loss training = 0.22346253054482595, best validation = 0.2651941329240799\n",
      "iteration 234: loss training = 0.22802039342267172, best validation = 0.2651941329240799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 237/300 [00:09<00:02, 27.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 235: loss training = 0.22769713401794434, best validation = 0.2651941329240799\n",
      "iteration 236: loss training = 0.22669770462172373, best validation = 0.2651941329240799\n",
      "iteration 237: loss training = 0.22508391525064195, best validation = 0.2651941329240799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 240/300 [00:09<00:02, 27.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 238: loss training = 0.224936557667596, best validation = 0.2651941329240799\n",
      "iteration 239: loss training = 0.23130814092499868, best validation = 0.2651941329240799\n",
      "iteration 240: loss training = 0.22706146112510137, best validation = 0.2651941329240799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 243/300 [00:09<00:02, 27.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 241: loss training = 0.22491781626428878, best validation = 0.2651941329240799\n",
      "iteration 242: loss training = 0.22802021673747472, best validation = 0.2651941329240799\n",
      "iteration 243: loss training = 0.22529113292694092, best validation = 0.2651941329240799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 246/300 [00:09<00:02, 25.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 244: loss training = 0.22834522809301103, best validation = 0.2651941329240799\n",
      "iteration 245: loss training = 0.22580241092613765, best validation = 0.2651941329240799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 249/300 [00:09<00:01, 25.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 246: loss training = 0.22787190760884965, best validation = 0.2651941329240799\n",
      "iteration 247: loss training = 0.22882630143846786, best validation = 0.2651941329240799\n",
      "iteration 248: loss training = 0.223883079630988, best validation = 0.2651941329240799\n",
      "iteration 249: loss training = 0.22726120267595565, best validation = 0.2651941329240799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 252/300 [00:09<00:01, 26.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 250: loss training = 0.22529727859156473, best validation = 0.2651941329240799\n",
      "iteration 251: loss training = 0.22929764219692775, best validation = 0.2651941329240799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 255/300 [00:09<00:01, 26.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 252: loss training = 0.22863387210028513, best validation = 0.2651941329240799\n",
      "iteration 253: loss training = 0.22654647060803004, best validation = 0.2651941329240799\n",
      "iteration 254: loss training = 0.22600889205932617, best validation = 0.2651941329240799\n",
      "iteration 255: loss training = 0.22736392063753946, best validation = 0.2651941329240799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 258/300 [00:09<00:01, 27.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 256: loss training = 0.22555071328367507, best validation = 0.2651941329240799\n",
      "iteration 257: loss training = 0.22705604774611338, best validation = 0.2651941329240799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 261/300 [00:10<00:01, 27.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 258: loss training = 0.22371263802051544, best validation = 0.2651941329240799\n",
      "iteration 259: loss training = 0.2278804076569421, best validation = 0.2651941329240799\n",
      "iteration 260: loss training = 0.22673597506114415, best validation = 0.2651941329240799\n",
      "iteration 261: loss training = 0.22914413682052068, best validation = 0.2651941329240799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 264/300 [00:10<00:01, 26.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 262: loss training = 0.2269961259194783, best validation = 0.2651941329240799\n",
      "iteration 263: loss training = 0.2258571982383728, best validation = 0.2651941329240799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 267/300 [00:10<00:01, 27.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 264: loss training = 0.22412057433809554, best validation = 0.2651941329240799\n",
      "iteration 265: loss training = 0.22779821072305953, best validation = 0.2651941329240799\n",
      "iteration 266: loss training = 0.22578967681952886, best validation = 0.2651941329240799\n",
      "iteration 267: loss training = 0.2294707660164152, best validation = 0.2651941329240799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 270/300 [00:10<00:01, 27.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 268: loss training = 0.2254024978194918, best validation = 0.2651941329240799\n",
      "iteration 269: loss training = 0.22334528820855276, best validation = 0.2651941329240799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 273/300 [00:10<00:00, 27.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 270: loss training = 0.22821160299437387, best validation = 0.2651941329240799\n",
      "iteration 271: loss training = 0.2303497280393328, best validation = 0.2651941329240799\n",
      "iteration 272: loss training = 0.23075569527489798, best validation = 0.2651941329240799\n",
      "iteration 273: loss training = 0.22732517761843546, best validation = 0.2651941329240799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 276/300 [00:10<00:00, 26.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 274: loss training = 0.22660332918167114, best validation = 0.2651941329240799\n",
      "iteration 275: loss training = 0.22703912002699717, best validation = 0.2651941329240799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 279/300 [00:10<00:00, 27.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 276: loss training = 0.22256227902003697, best validation = 0.2651941329240799\n",
      "iteration 277: loss training = 0.22892258635589055, best validation = 0.2651941329240799\n",
      "iteration 278: loss training = 0.2271822690963745, best validation = 0.2651941329240799\n",
      "iteration 279: loss training = 0.2287489984716688, best validation = 0.2651941329240799\n",
      "iteration 280: loss training = 0.2287050485610962, best validation = 0.2651941329240799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 285/300 [00:10<00:00, 24.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 281: loss training = 0.22315028948443277, best validation = 0.2651941329240799\n",
      "iteration 282: loss training = 0.22750865987368993, best validation = 0.2651941329240799\n",
      "iteration 283: loss training = 0.22844712223325456, best validation = 0.2651941329240799\n",
      "iteration 284: loss training = 0.229064479470253, best validation = 0.2651941329240799\n",
      "iteration 285: loss training = 0.22787498363426753, best validation = 0.2651941329240799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 288/300 [00:11<00:00, 23.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 286: loss training = 0.22585931633199965, best validation = 0.2651941329240799\n",
      "iteration 287: loss training = 0.2306657007762364, best validation = 0.2651941329240799\n",
      "iteration 288: loss training = 0.22565903408186777, best validation = 0.2651941329240799\n",
      "iteration 289: loss training = 0.22874910065105983, best validation = 0.2651941329240799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 291/300 [00:11<00:00, 23.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 290: loss training = 0.22752562591007777, best validation = 0.2651941329240799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 294/300 [00:11<00:00, 20.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 291: loss training = 0.22925252148083278, best validation = 0.2651941329240799\n",
      "iteration 292: loss training = 0.22503441359315599, best validation = 0.2651941329240799\n",
      "iteration 293: loss training = 0.2276210423026766, best validation = 0.2651941329240799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 297/300 [00:11<00:00, 21.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 294: loss training = 0.22684897482395172, best validation = 0.2651941329240799\n",
      "iteration 295: loss training = 0.22829284838267735, best validation = 0.2651941329240799\n",
      "iteration 296: loss training = 0.2270322846514838, best validation = 0.2651941329240799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:11<00:00, 25.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 297: loss training = 0.22702425931181228, best validation = 0.2651941329240799\n",
      "iteration 298: loss training = 0.22736228789602006, best validation = 0.2651941329240799\n",
      "iteration 299: loss training = 0.23004821368626185, best validation = 0.2651941329240799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.5710758141108921,\n",
       "  0.4712116888591221,\n",
       "  0.46353458932467867,\n",
       "  0.46095746755599976,\n",
       "  0.44955901162964956,\n",
       "  0.4356955034392221,\n",
       "  0.4177102063383375,\n",
       "  0.40321077193532673,\n",
       "  0.39312704120363506,\n",
       "  0.3884443938732147,\n",
       "  0.38553630879947115,\n",
       "  0.38611820340156555,\n",
       "  0.38412231632641386,\n",
       "  0.373800699199949,\n",
       "  0.3696348028523581,\n",
       "  0.36573647601263864,\n",
       "  0.3588628428322928,\n",
       "  0.35319691044943674,\n",
       "  0.34178524783679415,\n",
       "  0.32510347025735037,\n",
       "  0.32487425208091736,\n",
       "  0.3261845963341849,\n",
       "  0.33117343698229107,\n",
       "  0.30628874472209383,\n",
       "  0.29456324662481037,\n",
       "  0.3101255084787096,\n",
       "  0.3078127545969827,\n",
       "  0.29549034578459604,\n",
       "  0.285651649747576,\n",
       "  0.27724653482437134,\n",
       "  0.27418103388377596,\n",
       "  0.26983845233917236,\n",
       "  0.27041477390698027,\n",
       "  0.26281274003641947,\n",
       "  0.2606731951236725,\n",
       "  0.26247202285698484,\n",
       "  0.2599143513611385,\n",
       "  0.26351400571210043,\n",
       "  0.2585378757544926,\n",
       "  0.2565519000802721,\n",
       "  0.2558941330228533,\n",
       "  0.2539624571800232,\n",
       "  0.2514021566935948,\n",
       "  0.2561993492501123,\n",
       "  0.2528613976069859,\n",
       "  0.25185068590300425,\n",
       "  0.25168876349925995,\n",
       "  0.2454661407641002,\n",
       "  0.24787018980298722,\n",
       "  0.2467388255255563,\n",
       "  0.24751755169459752,\n",
       "  0.2467898109129497,\n",
       "  0.24578942784241267,\n",
       "  0.24613348501069204,\n",
       "  0.24286408722400665,\n",
       "  0.24005939066410065,\n",
       "  0.2394827284983226,\n",
       "  0.24131291678973607,\n",
       "  0.23884436701025283,\n",
       "  0.23931648901530675,\n",
       "  0.2343248724937439,\n",
       "  0.23386596143245697,\n",
       "  0.23264212693486894,\n",
       "  0.23441165259906224,\n",
       "  0.23808575102261134,\n",
       "  0.23338858144623892,\n",
       "  0.23051381749766214,\n",
       "  0.23337663922991073,\n",
       "  0.23484161921909877,\n",
       "  0.23376749455928802,\n",
       "  0.23268612793513707,\n",
       "  0.23337217952523912,\n",
       "  0.231155093227114,\n",
       "  0.23082431512219564,\n",
       "  0.23110992355006083,\n",
       "  0.23093762355191366,\n",
       "  0.23287890000002726,\n",
       "  0.22951711501393998,\n",
       "  0.22879086009093694,\n",
       "  0.22977187590939657,\n",
       "  0.22943588026932307,\n",
       "  0.2301454586642129,\n",
       "  0.22957350313663483,\n",
       "  0.23026608995028905,\n",
       "  0.2344042956829071,\n",
       "  0.2296550486768995,\n",
       "  0.2314765921660832,\n",
       "  0.22989534054483687,\n",
       "  0.2374074012041092,\n",
       "  0.22931704776627676,\n",
       "  0.22635370918682643,\n",
       "  0.23284460391317094,\n",
       "  0.2272774875164032,\n",
       "  0.22935215064457484,\n",
       "  0.2259791237967355,\n",
       "  0.2299734013421195,\n",
       "  0.22738205109323775,\n",
       "  0.22970502717154367,\n",
       "  0.22655547729560307,\n",
       "  0.22765967462744033,\n",
       "  0.2301414225782667,\n",
       "  0.22752676904201508,\n",
       "  0.22911103708403452,\n",
       "  0.22772190187658584,\n",
       "  0.23102188748972757,\n",
       "  0.22760935127735138,\n",
       "  0.23079029789992742,\n",
       "  0.2286376655101776,\n",
       "  0.2235229845557894,\n",
       "  0.23086610436439514,\n",
       "  0.227517836860248,\n",
       "  0.23184712656906672,\n",
       "  0.2263682974236352,\n",
       "  0.22990090080669948,\n",
       "  0.22849901233400619,\n",
       "  0.22914542044912065,\n",
       "  0.2276364756481988,\n",
       "  0.2263272830418178,\n",
       "  0.22761552461556026,\n",
       "  0.22880564630031586,\n",
       "  0.2290617333991187,\n",
       "  0.22653334055628097,\n",
       "  0.2264995915549142,\n",
       "  0.22643260870661056,\n",
       "  0.2247356538261686,\n",
       "  0.23064994173390524,\n",
       "  0.2263995579310826,\n",
       "  0.22815964903150285,\n",
       "  0.2282795203583581,\n",
       "  0.22811057525021688,\n",
       "  0.23022877744265965,\n",
       "  0.2267958245107106,\n",
       "  0.22959889258657182,\n",
       "  0.22842087277344295,\n",
       "  0.22845656744071416,\n",
       "  0.22959514600890024,\n",
       "  0.22345395173345292,\n",
       "  0.2290991906608854,\n",
       "  0.2266043871641159,\n",
       "  0.22869438145841872,\n",
       "  0.2251970555101122,\n",
       "  0.22577767074108124,\n",
       "  0.2254635351044791,\n",
       "  0.22687010041304997,\n",
       "  0.2263164988585881,\n",
       "  0.225773030093738,\n",
       "  0.2265675323350089,\n",
       "  0.22617631937776292,\n",
       "  0.22234334903103964,\n",
       "  0.23013016368661607,\n",
       "  0.2252974041870662,\n",
       "  0.22426737632070268,\n",
       "  0.22678320109844208,\n",
       "  0.22354229433195932,\n",
       "  0.2298459048782076,\n",
       "  0.230593347123691,\n",
       "  0.22450202916349685,\n",
       "  0.22612707316875458,\n",
       "  0.22657661778586252,\n",
       "  0.22755866604191916,\n",
       "  0.22577233186789922,\n",
       "  0.22634400640215194,\n",
       "  0.22553481587341853,\n",
       "  0.22507611768586294,\n",
       "  0.23145777412823268,\n",
       "  0.2252106751714434,\n",
       "  0.22528674134186336,\n",
       "  0.22672100152288163,\n",
       "  0.22621129027434758,\n",
       "  0.2286779454776219,\n",
       "  0.22902667948177882,\n",
       "  0.22922358981200627,\n",
       "  0.22377377109868185,\n",
       "  0.23185996285506658,\n",
       "  0.22657614946365356,\n",
       "  0.22616168005125864,\n",
       "  0.22893187829426356,\n",
       "  0.22379536500998906,\n",
       "  0.2269598458494459,\n",
       "  0.23013669678143092,\n",
       "  0.22512458051953996,\n",
       "  0.2301366925239563,\n",
       "  0.22647975385189056,\n",
       "  0.22989727982452937,\n",
       "  0.22367540214742934,\n",
       "  0.22756101829665049,\n",
       "  0.22406438205923354,\n",
       "  0.22744409101349966,\n",
       "  0.22380575324807847,\n",
       "  0.22255621637616838,\n",
       "  0.22475468686648778,\n",
       "  0.2275052453790392,\n",
       "  0.2253693150622504,\n",
       "  0.2249672327722822,\n",
       "  0.2253518189702715,\n",
       "  0.22736825687544687,\n",
       "  0.22411203810146876,\n",
       "  0.22637256979942322,\n",
       "  0.22884372089590346,\n",
       "  0.22724583745002747,\n",
       "  0.2287029560123171,\n",
       "  0.22686525966439927,\n",
       "  0.22755352301256998,\n",
       "  0.22847458294459752,\n",
       "  0.22820267294134414,\n",
       "  0.22293455473014287,\n",
       "  0.22717545287949698,\n",
       "  0.22863514508519853,\n",
       "  0.22692173719406128,\n",
       "  0.22841162979602814,\n",
       "  0.22971912367003305,\n",
       "  0.225399021591459,\n",
       "  0.23108779532568796,\n",
       "  0.22824055595057352,\n",
       "  0.22647123890263693,\n",
       "  0.22602802302156175,\n",
       "  0.22643693217209407,\n",
       "  0.2304830742733819,\n",
       "  0.22720360330172948,\n",
       "  0.23035561399800436,\n",
       "  0.22869074983256205,\n",
       "  0.22429836222103663,\n",
       "  0.2258522765977042,\n",
       "  0.22806079472814286,\n",
       "  0.23041264287063054,\n",
       "  0.22825097611972264,\n",
       "  0.2257236476455416,\n",
       "  0.22476987540721893,\n",
       "  0.22596319445541926,\n",
       "  0.22688798606395721,\n",
       "  0.2293681161744254,\n",
       "  0.22865883367402212,\n",
       "  0.2272825837135315,\n",
       "  0.22346253054482595,\n",
       "  0.22802039342267172,\n",
       "  0.22769713401794434,\n",
       "  0.22669770462172373,\n",
       "  0.22508391525064195,\n",
       "  0.224936557667596,\n",
       "  0.23130814092499868,\n",
       "  0.22706146112510137,\n",
       "  0.22491781626428878,\n",
       "  0.22802021673747472,\n",
       "  0.22529113292694092,\n",
       "  0.22834522809301103,\n",
       "  0.22580241092613765,\n",
       "  0.22787190760884965,\n",
       "  0.22882630143846786,\n",
       "  0.223883079630988,\n",
       "  0.22726120267595565,\n",
       "  0.22529727859156473,\n",
       "  0.22929764219692775,\n",
       "  0.22863387210028513,\n",
       "  0.22654647060803004,\n",
       "  0.22600889205932617,\n",
       "  0.22736392063753946,\n",
       "  0.22555071328367507,\n",
       "  0.22705604774611338,\n",
       "  0.22371263802051544,\n",
       "  0.2278804076569421,\n",
       "  0.22673597506114415,\n",
       "  0.22914413682052068,\n",
       "  0.2269961259194783,\n",
       "  0.2258571982383728,\n",
       "  0.22412057433809554,\n",
       "  0.22779821072305953,\n",
       "  0.22578967681952886,\n",
       "  0.2294707660164152,\n",
       "  0.2254024978194918,\n",
       "  0.22334528820855276,\n",
       "  0.22821160299437387,\n",
       "  0.2303497280393328,\n",
       "  0.23075569527489798,\n",
       "  0.22732517761843546,\n",
       "  0.22660332918167114,\n",
       "  0.22703912002699717,\n",
       "  0.22256227902003697,\n",
       "  0.22892258635589055,\n",
       "  0.2271822690963745,\n",
       "  0.2287489984716688,\n",
       "  0.2287050485610962,\n",
       "  0.22315028948443277,\n",
       "  0.22750865987368993,\n",
       "  0.22844712223325456,\n",
       "  0.229064479470253,\n",
       "  0.22787498363426753,\n",
       "  0.22585931633199965,\n",
       "  0.2306657007762364,\n",
       "  0.22565903408186777,\n",
       "  0.22874910065105983,\n",
       "  0.22752562591007777,\n",
       "  0.22925252148083278,\n",
       "  0.22503441359315599,\n",
       "  0.2276210423026766,\n",
       "  0.22684897482395172,\n",
       "  0.22829284838267735,\n",
       "  0.2270322846514838,\n",
       "  0.22702425931181228,\n",
       "  0.22736228789602006,\n",
       "  0.23004821368626185],\n",
       " [0.46782033145427704,\n",
       "  0.47015076875686646,\n",
       "  0.47407568991184235,\n",
       "  0.4661186933517456,\n",
       "  0.4460771530866623,\n",
       "  0.42884834110736847,\n",
       "  0.4164275825023651,\n",
       "  0.41249722242355347,\n",
       "  0.40606047213077545,\n",
       "  0.4160528630018234,\n",
       "  0.40336865186691284,\n",
       "  0.4010127931833267,\n",
       "  0.3971506804227829,\n",
       "  0.39042073488235474,\n",
       "  0.3957694172859192,\n",
       "  0.385025218129158,\n",
       "  0.37786000967025757,\n",
       "  0.36761675775051117,\n",
       "  0.3577103912830353,\n",
       "  0.3476676642894745,\n",
       "  0.35555507242679596,\n",
       "  0.36076004803180695,\n",
       "  0.3462018221616745,\n",
       "  0.32128243148326874,\n",
       "  0.31986190378665924,\n",
       "  0.3394176512956619,\n",
       "  0.3231133371591568,\n",
       "  0.31753070652484894,\n",
       "  0.3064710944890976,\n",
       "  0.303581178188324,\n",
       "  0.2992022782564163,\n",
       "  0.2980645149946213,\n",
       "  0.2939324527978897,\n",
       "  0.2930019795894623,\n",
       "  0.2898593693971634,\n",
       "  0.28758497536182404,\n",
       "  0.2879662662744522,\n",
       "  0.2888345271348953,\n",
       "  0.28494445979595184,\n",
       "  0.28472496569156647,\n",
       "  0.283376082777977,\n",
       "  0.28200414776802063,\n",
       "  0.28486059606075287,\n",
       "  0.2833637297153473,\n",
       "  0.2821893244981766,\n",
       "  0.2807650715112686,\n",
       "  0.2789170444011688,\n",
       "  0.28237393498420715,\n",
       "  0.27823740243911743,\n",
       "  0.27928537130355835,\n",
       "  0.2779146581888199,\n",
       "  0.2761964052915573,\n",
       "  0.2772544175386429,\n",
       "  0.2766566127538681,\n",
       "  0.27589279413223267,\n",
       "  0.276347279548645,\n",
       "  0.27378931641578674,\n",
       "  0.27016590535640717,\n",
       "  0.2724490463733673,\n",
       "  0.2730192095041275,\n",
       "  0.27167898416519165,\n",
       "  0.2708740830421448,\n",
       "  0.2702227681875229,\n",
       "  0.2699168026447296,\n",
       "  0.269957035779953,\n",
       "  0.26975786685943604,\n",
       "  0.26993797719478607,\n",
       "  0.26992267370224,\n",
       "  0.2695755064487457,\n",
       "  0.2689654380083084,\n",
       "  0.26925455033779144,\n",
       "  0.26931101083755493,\n",
       "  0.26925623416900635,\n",
       "  0.26878775656223297,\n",
       "  0.2688130736351013,\n",
       "  0.2687039226293564,\n",
       "  0.26853545010089874,\n",
       "  0.2683413028717041,\n",
       "  0.2684352844953537,\n",
       "  0.26832590997219086,\n",
       "  0.26800772547721863,\n",
       "  0.26785340905189514,\n",
       "  0.26757414638996124,\n",
       "  0.26757530868053436,\n",
       "  0.2676451802253723,\n",
       "  0.2669088989496231,\n",
       "  0.26667971909046173,\n",
       "  0.2665656805038452,\n",
       "  0.2664273679256439,\n",
       "  0.2667149752378464,\n",
       "  0.26672889292240143,\n",
       "  0.266563355922699,\n",
       "  0.2664647847414017,\n",
       "  0.26642362773418427,\n",
       "  0.2664274722337723,\n",
       "  0.2664235085248947,\n",
       "  0.26639822125434875,\n",
       "  0.26639503240585327,\n",
       "  0.2663690000772476,\n",
       "  0.26636604964733124,\n",
       "  0.2662985920906067,\n",
       "  0.26624172925949097,\n",
       "  0.2662689834833145,\n",
       "  0.26635245978832245,\n",
       "  0.266323983669281,\n",
       "  0.2662722021341324,\n",
       "  0.2662365436553955,\n",
       "  0.2662125825881958,\n",
       "  0.2660883963108063,\n",
       "  0.2660040110349655,\n",
       "  0.26598140597343445,\n",
       "  0.2658986747264862,\n",
       "  0.26585492491722107,\n",
       "  0.26525233685970306,\n",
       "  0.2651941329240799,\n",
       "  0.26537230610847473,\n",
       "  0.26527850329875946,\n",
       "  0.2654188722372055,\n",
       "  0.2654596120119095,\n",
       "  0.2656787931919098,\n",
       "  0.26565997302532196,\n",
       "  0.26564671099185944,\n",
       "  0.26563309133052826,\n",
       "  0.265615850687027,\n",
       "  0.2656024843454361,\n",
       "  0.2655928134918213,\n",
       "  0.2655794769525528,\n",
       "  0.2655615955591202,\n",
       "  0.26554495096206665,\n",
       "  0.26554907858371735,\n",
       "  0.26555828750133514,\n",
       "  0.2655737102031708,\n",
       "  0.2655602693557739,\n",
       "  0.2655467987060547,\n",
       "  0.2655270844697952,\n",
       "  0.26549915969371796,\n",
       "  0.2654843181371689,\n",
       "  0.26547636091709137,\n",
       "  0.26548293232917786,\n",
       "  0.26549287140369415,\n",
       "  0.26549430191516876,\n",
       "  0.26550109684467316,\n",
       "  0.26551012694835663,\n",
       "  0.2655055969953537,\n",
       "  0.2654830068349838,\n",
       "  0.26545771956443787,\n",
       "  0.26545415818691254,\n",
       "  0.2654443085193634,\n",
       "  0.26542942225933075,\n",
       "  0.26543064415454865,\n",
       "  0.2654290944337845,\n",
       "  0.26542577147483826,\n",
       "  0.26542362570762634,\n",
       "  0.26542235910892487,\n",
       "  0.26542356610298157,\n",
       "  0.2654242068529129,\n",
       "  0.26542121171951294,\n",
       "  0.26541754603385925,\n",
       "  0.26541365683078766,\n",
       "  0.2654121369123459,\n",
       "  0.2654111832380295,\n",
       "  0.2654101550579071,\n",
       "  0.26541249454021454,\n",
       "  0.26541072130203247,\n",
       "  0.2654075026512146,\n",
       "  0.26540644466876984,\n",
       "  0.26540407538414,\n",
       "  0.26540471613407135,\n",
       "  0.2654014378786087,\n",
       "  0.26540111005306244,\n",
       "  0.2654055655002594,\n",
       "  0.265406534075737,\n",
       "  0.2654091566801071,\n",
       "  0.265413373708725,\n",
       "  0.26541711390018463,\n",
       "  0.2654217779636383,\n",
       "  0.26541927456855774,\n",
       "  0.26541943848133087,\n",
       "  0.26541903614997864,\n",
       "  0.265414834022522,\n",
       "  0.2654144912958145,\n",
       "  0.26541441679000854,\n",
       "  0.2654139995574951,\n",
       "  0.26541364192962646,\n",
       "  0.26541393995285034,\n",
       "  0.2654128074645996,\n",
       "  0.2654130458831787,\n",
       "  0.2654137760400772,\n",
       "  0.26541362702846527,\n",
       "  0.2654135972261429,\n",
       "  0.26541316509246826,\n",
       "  0.2654125243425369,\n",
       "  0.26541154086589813,\n",
       "  0.26541097462177277,\n",
       "  0.2654103487730026,\n",
       "  0.2654099017381668,\n",
       "  0.2654097378253937,\n",
       "  0.2654101699590683,\n",
       "  0.2654101848602295,\n",
       "  0.2654103487730026,\n",
       "  0.2654106765985489,\n",
       "  0.26541005074977875,\n",
       "  0.2654091566801071,\n",
       "  0.2654096931219101,\n",
       "  0.26540933549404144,\n",
       "  0.26540881395339966,\n",
       "  0.2654081732034683,\n",
       "  0.26540781557559967,\n",
       "  0.26540739834308624,\n",
       "  0.2654065042734146,\n",
       "  0.26540637016296387,\n",
       "  0.26540639996528625,\n",
       "  0.26540619134902954,\n",
       "  0.265405997633934,\n",
       "  0.26540596783161163,\n",
       "  0.26540592312812805,\n",
       "  0.2654058337211609,\n",
       "  0.2654057443141937,\n",
       "  0.2654055505990982,\n",
       "  0.2654052972793579,\n",
       "  0.2654050141572952,\n",
       "  0.26540499925613403,\n",
       "  0.26540495455265045,\n",
       "  0.2654048502445221,\n",
       "  0.2654045969247818,\n",
       "  0.2654045522212982,\n",
       "  0.26540468633174896,\n",
       "  0.2654046565294266,\n",
       "  0.2654046565294266,\n",
       "  0.2654045671224594,\n",
       "  0.26540443301200867,\n",
       "  0.26540422439575195,\n",
       "  0.26540425419807434,\n",
       "  0.2654041200876236,\n",
       "  0.2654038518667221,\n",
       "  0.26540377736091614,\n",
       "  0.26540352404117584,\n",
       "  0.2654035985469818,\n",
       "  0.26540355384349823,\n",
       "  0.26540355384349823,\n",
       "  0.26540352404117584,\n",
       "  0.26540352404117584,\n",
       "  0.26540350914001465,\n",
       "  0.26540350914001465,\n",
       "  0.26540353894233704,\n",
       "  0.26540352404117584,\n",
       "  0.26540353894233704,\n",
       "  0.26540353894233704,\n",
       "  0.26540352404117584,\n",
       "  0.2654035985469818,\n",
       "  0.2654035836458206,\n",
       "  0.265403613448143,\n",
       "  0.2654036581516266,\n",
       "  0.2654036730527878,\n",
       "  0.26540370285511017,\n",
       "  0.26540373265743256,\n",
       "  0.26540373265743256,\n",
       "  0.26540373265743256,\n",
       "  0.26540374755859375,\n",
       "  0.26540374755859375,\n",
       "  0.26540370285511017,\n",
       "  0.2654036730527878,\n",
       "  0.2654036581516266,\n",
       "  0.2654035687446594,\n",
       "  0.26540353894233704,\n",
       "  0.26540352404117584,\n",
       "  0.26540352404117584,\n",
       "  0.26540349423885345,\n",
       "  0.26540349423885345,\n",
       "  0.26540352404117584,\n",
       "  0.26540352404117584,\n",
       "  0.26540352404117584,\n",
       "  0.26540352404117584,\n",
       "  0.26540349423885345,\n",
       "  0.26540352404117584,\n",
       "  0.26540349423885345,\n",
       "  0.26540352404117584,\n",
       "  0.26540353894233704,\n",
       "  0.26540353894233704,\n",
       "  0.26540350914001465,\n",
       "  0.26540352404117584,\n",
       "  0.26540350914001465,\n",
       "  0.26540350914001465,\n",
       "  0.26540352404117584,\n",
       "  0.26540349423885345,\n",
       "  0.26540349423885345,\n",
       "  0.26540350914001465,\n",
       "  0.26540352404117584,\n",
       "  0.26540352404117584,\n",
       "  0.26540350914001465,\n",
       "  0.26540352404117584,\n",
       "  0.26540349423885345,\n",
       "  0.26540347933769226,\n",
       "  0.26540349423885345,\n",
       "  0.26540349423885345,\n",
       "  0.26540349423885345,\n",
       "  0.26540349423885345,\n",
       "  0.26540350914001465,\n",
       "  0.26540349423885345,\n",
       "  0.26540349423885345])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da_music_v2 = DA_MUSIC_v2(m, d, array, dev)\n",
    "train(da_music_v2, nbEpoches, lr, wd, train_loader, valid_loader, path+'da_music_v2_'+str(snr)+'dB_ula.pth', train_func, valid_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0: loss training = 0.575290152004787, best validation = 0.5184966176748276\n",
      "iteration 1: loss training = 0.5230628337178912, best validation = 0.5155826807022095\n",
      "iteration 2: loss training = 0.5041140913963318, best validation = 0.5007872879505157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 4/300 [00:00<00:09, 31.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 3: loss training = 0.49086094328335356, best validation = 0.47202466428279877\n",
      "iteration 4: loss training = 0.4691765947001321, best validation = 0.46458882093429565\n",
      "iteration 5: loss training = 0.4486918108803885, best validation = 0.4442215859889984\n",
      "iteration 6: loss training = 0.4212984187262399, best validation = 0.41944898664951324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 8/300 [00:00<00:09, 32.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 7: loss training = 0.39928435002054485, best validation = 0.40270404517650604\n",
      "iteration 8: loss training = 0.369526390518461, best validation = 0.3797880858182907\n",
      "iteration 9: loss training = 0.3500272716794695, best validation = 0.36804574728012085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 12/300 [00:00<00:08, 33.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 10: loss training = 0.3345822606767927, best validation = 0.3601859211921692\n",
      "iteration 11: loss training = 0.3133710197040013, best validation = 0.33271245658397675\n",
      "iteration 12: loss training = 0.30494214381490437, best validation = 0.3246709257364273\n",
      "iteration 13: loss training = 0.27937967010906767, best validation = 0.3094460219144821\n",
      "iteration 14: loss training = 0.2627727176461901, best validation = 0.3044036328792572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 16/300 [00:00<00:08, 34.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 15: loss training = 0.25026497883456095, best validation = 0.30107082426548004\n",
      "iteration 16: loss training = 0.23924501240253448, best validation = 0.2818908840417862\n",
      "iteration 17: loss training = 0.22595365984099253, best validation = 0.2693510502576828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 20/300 [00:00<00:08, 32.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 18: loss training = 0.2104939477784293, best validation = 0.26030271500349045\n",
      "iteration 19: loss training = 0.2064917598451887, best validation = 0.26030271500349045\n",
      "iteration 20: loss training = 0.19517844702516282, best validation = 0.23973448574543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 24/300 [00:00<00:08, 31.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 21: loss training = 0.18246627066816604, best validation = 0.2287551462650299\n",
      "iteration 22: loss training = 0.17331779641764505, best validation = 0.22797898203134537\n",
      "iteration 23: loss training = 0.16754949518612453, best validation = 0.22797898203134537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 28/300 [00:00<00:08, 31.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 24: loss training = 0.1631815071616854, best validation = 0.20941660553216934\n",
      "iteration 25: loss training = 0.15254596514361246, best validation = 0.19675160199403763\n",
      "iteration 26: loss training = 0.14381887870175497, best validation = 0.19675160199403763\n",
      "iteration 27: loss training = 0.1549426657812936, best validation = 0.19675160199403763\n",
      "iteration 28: loss training = 0.1610946080514363, best validation = 0.1854076012969017\n",
      "iteration 29: loss training = 0.1534518301486969, best validation = 0.1854076012969017\n",
      "iteration 30: loss training = 0.13248300552368164, best validation = 0.18095802515745163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 32/300 [00:00<00:08, 32.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 31: loss training = 0.125871727509158, best validation = 0.17522932589054108\n",
      "iteration 32: loss training = 0.11875968320029122, best validation = 0.171552374958992\n",
      "iteration 33: loss training = 0.11395370002303805, best validation = 0.17030829191207886\n",
      "iteration 34: loss training = 0.11297257031713213, best validation = 0.17030829191207886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 36/300 [00:01<00:08, 32.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 35: loss training = 0.10898739738123757, best validation = 0.16918162256479263\n",
      "iteration 36: loss training = 0.1078989857009479, best validation = 0.16918162256479263\n",
      "iteration 37: loss training = 0.10582556469099862, best validation = 0.16778786480426788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 40/300 [00:01<00:07, 32.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 38: loss training = 0.1020444535783359, best validation = 0.16778786480426788\n",
      "iteration 39: loss training = 0.10236945961202894, best validation = 0.16356462985277176\n",
      "iteration 40: loss training = 0.09940023933138166, best validation = 0.16356462985277176\n",
      "iteration 41: loss training = 0.09771742245980672, best validation = 0.16327181458473206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 44/300 [00:01<00:07, 32.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 42: loss training = 0.09717284994465965, best validation = 0.16327181458473206\n",
      "iteration 43: loss training = 0.09759011438914708, best validation = 0.1626342311501503\n",
      "iteration 44: loss training = 0.09628841280937195, best validation = 0.1626342311501503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 48/300 [00:01<00:07, 32.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 45: loss training = 0.09626735108239311, best validation = 0.1626342311501503\n",
      "iteration 46: loss training = 0.09479719613279615, best validation = 0.16205324977636337\n",
      "iteration 47: loss training = 0.0924577649150576, best validation = 0.16205324977636337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 52/300 [00:01<00:07, 31.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 48: loss training = 0.09190578013658524, best validation = 0.16205324977636337\n",
      "iteration 49: loss training = 0.09019143240792411, best validation = 0.16205324977636337\n",
      "iteration 50: loss training = 0.09050844183989934, best validation = 0.16190502047538757\n",
      "iteration 51: loss training = 0.08796270830290658, best validation = 0.16056329756975174\n",
      "iteration 52: loss training = 0.08815826049872807, best validation = 0.1604316085577011\n",
      "iteration 53: loss training = 0.08661599457263947, best validation = 0.16001196950674057\n",
      "iteration 54: loss training = 0.08668576180934906, best validation = 0.16001196950674057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 56/300 [00:01<00:07, 31.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 55: loss training = 0.08836132075105395, best validation = 0.16001196950674057\n",
      "iteration 56: loss training = 0.08443488074200493, best validation = 0.1588771864771843\n",
      "iteration 57: loss training = 0.08491875550576619, best validation = 0.1588771864771843\n",
      "iteration 58: loss training = 0.08451614316020693, best validation = 0.1582939401268959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 60/300 [00:01<00:07, 32.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 59: loss training = 0.08474647998809814, best validation = 0.1582939401268959\n",
      "iteration 60: loss training = 0.0823140378509249, best validation = 0.1582939401268959\n",
      "iteration 61: loss training = 0.08022492698260716, best validation = 0.1582939401268959\n",
      "iteration 62: loss training = 0.07878885418176651, best validation = 0.15800585597753525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 64/300 [00:01<00:06, 34.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 63: loss training = 0.07925485074520111, best validation = 0.15755242854356766\n",
      "iteration 64: loss training = 0.07746279665402003, best validation = 0.1575174406170845\n",
      "iteration 65: loss training = 0.07761583370821816, best validation = 0.1575174406170845\n",
      "iteration 66: loss training = 0.07659087755850383, best validation = 0.1575174406170845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 68/300 [00:02<00:06, 35.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 67: loss training = 0.0779504297035081, best validation = 0.1572900265455246\n",
      "iteration 68: loss training = 0.07734409613268715, best validation = 0.1572900265455246\n",
      "iteration 69: loss training = 0.07812984713486262, best validation = 0.1572900265455246\n",
      "iteration 70: loss training = 0.07589581928082875, best validation = 0.1569761112332344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 72/300 [00:02<00:06, 36.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 71: loss training = 0.07536151047263827, best validation = 0.1569761112332344\n",
      "iteration 72: loss training = 0.07712305337190628, best validation = 0.1569761112332344\n",
      "iteration 73: loss training = 0.07616574742964335, best validation = 0.1568555161356926\n",
      "iteration 74: loss training = 0.07490397564002446, best validation = 0.15669476985931396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 76/300 [00:02<00:06, 35.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 75: loss training = 0.07518224950347628, best validation = 0.15649963915348053\n",
      "iteration 76: loss training = 0.07534153014421463, best validation = 0.15649963915348053\n",
      "iteration 77: loss training = 0.07578128895589284, best validation = 0.156425841152668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 80/300 [00:02<00:06, 34.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 78: loss training = 0.0750511395079749, best validation = 0.15636491775512695\n",
      "iteration 79: loss training = 0.07512409559317998, best validation = 0.15636491775512695\n",
      "iteration 80: loss training = 0.07687919586896896, best validation = 0.15636491775512695\n",
      "iteration 81: loss training = 0.0759180241397449, best validation = 0.15636491775512695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 84/300 [00:02<00:06, 33.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 82: loss training = 0.0760098227432796, best validation = 0.15633992105722427\n",
      "iteration 83: loss training = 0.07471464042152677, best validation = 0.15633992105722427\n",
      "iteration 84: loss training = 0.07406539150646754, best validation = 0.15600571781396866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 88/300 [00:02<00:06, 34.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 85: loss training = 0.07423896661826543, best validation = 0.15600571781396866\n",
      "iteration 86: loss training = 0.07561293563672475, best validation = 0.15600571781396866\n",
      "iteration 87: loss training = 0.07449083988155637, best validation = 0.1558568924665451\n",
      "iteration 88: loss training = 0.07413456695420402, best validation = 0.15518786758184433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 92/300 [00:02<00:06, 32.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 89: loss training = 0.07280060169952256, best validation = 0.15518786758184433\n",
      "iteration 90: loss training = 0.07356831324951989, best validation = 0.15518786758184433\n",
      "iteration 91: loss training = 0.0737442257148879, best validation = 0.15518786758184433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 96/300 [00:02<00:06, 33.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 92: loss training = 0.0727660304733685, best validation = 0.15518786758184433\n",
      "iteration 93: loss training = 0.07278582666601453, best validation = 0.15518786758184433\n",
      "iteration 94: loss training = 0.0724650312747274, best validation = 0.15518786758184433\n",
      "iteration 95: loss training = 0.07396888732910156, best validation = 0.15518786758184433\n",
      "iteration 96: loss training = 0.07383297596658979, best validation = 0.15518786758184433\n",
      "iteration 97: loss training = 0.07362606908593859, best validation = 0.15518786758184433\n",
      "iteration 98: loss training = 0.07465571484395436, best validation = 0.15518786758184433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 100/300 [00:03<00:06, 32.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 99: loss training = 0.07326418587139674, best validation = 0.15518786758184433\n",
      "iteration 100: loss training = 0.07260005176067352, best validation = 0.15518786758184433\n",
      "iteration 101: loss training = 0.07299762006316866, best validation = 0.15518786758184433\n",
      "iteration 102: loss training = 0.07339955759899956, best validation = 0.15518786758184433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 104/300 [00:03<00:06, 32.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 103: loss training = 0.07229577749967575, best validation = 0.15518786758184433\n",
      "iteration 104: loss training = 0.07187507408005851, best validation = 0.15518786758184433\n",
      "iteration 105: loss training = 0.07342934714896339, best validation = 0.15518786758184433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 108/300 [00:03<00:06, 31.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 106: loss training = 0.07220896439892906, best validation = 0.15518786758184433\n",
      "iteration 107: loss training = 0.07349256638969694, best validation = 0.15518786758184433\n",
      "iteration 108: loss training = 0.07284632963793618, best validation = 0.15518786758184433\n",
      "iteration 109: loss training = 0.07299777013914925, best validation = 0.15518786758184433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 112/300 [00:03<00:06, 31.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 110: loss training = 0.07299882386411939, best validation = 0.15518786758184433\n",
      "iteration 111: loss training = 0.07144812015550477, best validation = 0.15518786758184433\n",
      "iteration 112: loss training = 0.07353551685810089, best validation = 0.15518786758184433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 116/300 [00:03<00:05, 32.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 113: loss training = 0.072867109307221, best validation = 0.15518786758184433\n",
      "iteration 114: loss training = 0.0725016061748777, best validation = 0.15518786758184433\n",
      "iteration 115: loss training = 0.07307511674506324, best validation = 0.15518786758184433\n",
      "iteration 116: loss training = 0.07253750094345637, best validation = 0.15518786758184433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 120/300 [00:03<00:05, 32.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 117: loss training = 0.07138203403779439, best validation = 0.15518786758184433\n",
      "iteration 118: loss training = 0.07266807236841746, best validation = 0.15518786758184433\n",
      "iteration 119: loss training = 0.07164516087089266, best validation = 0.15518786758184433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 124/300 [00:03<00:05, 32.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 120: loss training = 0.07387702486344747, best validation = 0.15518786758184433\n",
      "iteration 121: loss training = 0.07223169505596161, best validation = 0.15518786758184433\n",
      "iteration 122: loss training = 0.07163260557821818, best validation = 0.15518786758184433\n",
      "iteration 123: loss training = 0.0715841640319143, best validation = 0.15518786758184433\n",
      "iteration 124: loss training = 0.0716453662940434, best validation = 0.15518786758184433\n",
      "iteration 125: loss training = 0.07284687459468842, best validation = 0.15518786758184433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 128/300 [00:03<00:05, 30.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 126: loss training = 0.07193449884653091, best validation = 0.15518786758184433\n",
      "iteration 127: loss training = 0.07207453463758741, best validation = 0.15518786758184433\n",
      "iteration 128: loss training = 0.07190864852496556, best validation = 0.15518786758184433\n",
      "iteration 129: loss training = 0.07116275812898364, best validation = 0.15518786758184433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 132/300 [00:04<00:05, 31.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 130: loss training = 0.07276767918041774, best validation = 0.15518786758184433\n",
      "iteration 131: loss training = 0.07251773455313273, best validation = 0.15518786758184433\n",
      "iteration 132: loss training = 0.07213300785848073, best validation = 0.15518786758184433\n",
      "iteration 133: loss training = 0.07140689236777169, best validation = 0.15518786758184433\n",
      "iteration 134: loss training = 0.07325071415730885, best validation = 0.15518786758184433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 140/300 [00:04<00:05, 30.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 135: loss training = 0.07180818915367126, best validation = 0.15518786758184433\n",
      "iteration 136: loss training = 0.07231793339763369, best validation = 0.15518786758184433\n",
      "iteration 137: loss training = 0.07324156803744179, best validation = 0.15518786758184433\n",
      "iteration 138: loss training = 0.07316202138151441, best validation = 0.15518786758184433\n",
      "iteration 139: loss training = 0.0707452403647559, best validation = 0.15518786758184433\n",
      "iteration 140: loss training = 0.07153690819229398, best validation = 0.15518786758184433\n",
      "iteration 141: loss training = 0.07233368498938424, best validation = 0.15518786758184433\n",
      "iteration 142: loss training = 0.0724339070064681, best validation = 0.15518786758184433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 148/300 [00:04<00:04, 33.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 143: loss training = 0.07262960289205823, best validation = 0.15518786758184433\n",
      "iteration 144: loss training = 0.07299315610102244, best validation = 0.15518786758184433\n",
      "iteration 145: loss training = 0.07187151376690183, best validation = 0.15518786758184433\n",
      "iteration 146: loss training = 0.07359055961881365, best validation = 0.15518786758184433\n",
      "iteration 147: loss training = 0.07297112792730331, best validation = 0.15518786758184433\n",
      "iteration 148: loss training = 0.07335166846002851, best validation = 0.15518786758184433\n",
      "iteration 149: loss training = 0.0727966810975756, best validation = 0.15518786758184433\n",
      "iteration 150: loss training = 0.07154869926827294, best validation = 0.15518786758184433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 156/300 [00:04<00:04, 35.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 151: loss training = 0.07164907029696874, best validation = 0.15518786758184433\n",
      "iteration 152: loss training = 0.07344281886305128, best validation = 0.15518786758184433\n",
      "iteration 153: loss training = 0.0727457446711404, best validation = 0.15518786758184433\n",
      "iteration 154: loss training = 0.07200802756207329, best validation = 0.15518786758184433\n",
      "iteration 155: loss training = 0.07291985941784722, best validation = 0.15518786758184433\n",
      "iteration 156: loss training = 0.07153021437781197, best validation = 0.15518786758184433\n",
      "iteration 157: loss training = 0.07424401066132955, best validation = 0.15518786758184433\n",
      "iteration 158: loss training = 0.07194850806679044, best validation = 0.15518786758184433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 164/300 [00:04<00:03, 35.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 159: loss training = 0.07066672987171582, best validation = 0.15518786758184433\n",
      "iteration 160: loss training = 0.07131297247750419, best validation = 0.15518786758184433\n",
      "iteration 161: loss training = 0.07250082279954638, best validation = 0.15518786758184433\n",
      "iteration 162: loss training = 0.07229153705494744, best validation = 0.15518786758184433\n",
      "iteration 163: loss training = 0.07235017205987658, best validation = 0.15518786758184433\n",
      "iteration 164: loss training = 0.07178971277815956, best validation = 0.15518786758184433\n",
      "iteration 165: loss training = 0.0710394520844732, best validation = 0.15518786758184433\n",
      "iteration 166: loss training = 0.07302692319665637, best validation = 0.15518786758184433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 172/300 [00:05<00:03, 35.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 167: loss training = 0.07277927760566984, best validation = 0.15518786758184433\n",
      "iteration 168: loss training = 0.07227397284337453, best validation = 0.15518786758184433\n",
      "iteration 169: loss training = 0.07156947361571449, best validation = 0.15518786758184433\n",
      "iteration 170: loss training = 0.07168517155306679, best validation = 0.15518786758184433\n",
      "iteration 171: loss training = 0.07245001303298133, best validation = 0.15518786758184433\n",
      "iteration 172: loss training = 0.0715297396693911, best validation = 0.15518786758184433\n",
      "iteration 173: loss training = 0.07319753084863935, best validation = 0.15518786758184433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 176/300 [00:05<00:03, 34.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 174: loss training = 0.07225197234324046, best validation = 0.15518786758184433\n",
      "iteration 175: loss training = 0.07292928546667099, best validation = 0.15518786758184433\n",
      "iteration 176: loss training = 0.07044703513383865, best validation = 0.15518786758184433\n",
      "iteration 177: loss training = 0.07427361075367246, best validation = 0.15518786758184433\n",
      "iteration 178: loss training = 0.07201183480875832, best validation = 0.15518786758184433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 180/300 [00:05<00:03, 34.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 179: loss training = 0.07274116895028523, best validation = 0.15518786758184433\n",
      "iteration 180: loss training = 0.07126408496073314, best validation = 0.15518786758184433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 184/300 [00:05<00:03, 34.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 181: loss training = 0.07269219521965299, best validation = 0.15518786758184433\n",
      "iteration 182: loss training = 0.07188296743801662, best validation = 0.15518786758184433\n",
      "iteration 183: loss training = 0.07181128433772496, best validation = 0.15518786758184433\n",
      "iteration 184: loss training = 0.0724478353347097, best validation = 0.15518786758184433\n",
      "iteration 185: loss training = 0.07182850156511579, best validation = 0.15518786758184433\n",
      "iteration 186: loss training = 0.0730134706412043, best validation = 0.15518786758184433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 188/300 [00:05<00:03, 35.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 187: loss training = 0.07293280639818736, best validation = 0.15518786758184433\n",
      "iteration 188: loss training = 0.0720451261316027, best validation = 0.15518786758184433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 192/300 [00:05<00:03, 35.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 189: loss training = 0.07129467598029546, best validation = 0.15518786758184433\n",
      "iteration 190: loss training = 0.07029998089585986, best validation = 0.15518786758184433\n",
      "iteration 191: loss training = 0.07275629469326564, best validation = 0.15518786758184433\n",
      "iteration 192: loss training = 0.0715107513325555, best validation = 0.15518786758184433\n",
      "iteration 193: loss training = 0.07172681497676033, best validation = 0.15518786758184433\n",
      "iteration 194: loss training = 0.07235914468765259, best validation = 0.15518786758184433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 196/300 [00:05<00:02, 35.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 195: loss training = 0.07183409482240677, best validation = 0.15518786758184433\n",
      "iteration 196: loss training = 0.07243814106498446, best validation = 0.15518786758184433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 200/300 [00:05<00:02, 35.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 197: loss training = 0.07376462540456227, best validation = 0.15518786758184433\n",
      "iteration 198: loss training = 0.07163174769708089, best validation = 0.15518786758184433\n",
      "iteration 199: loss training = 0.07147658403430666, best validation = 0.15518786758184433\n",
      "iteration 200: loss training = 0.07202456040041787, best validation = 0.15518786758184433\n",
      "iteration 201: loss training = 0.07056256649749619, best validation = 0.15518786758184433\n",
      "iteration 202: loss training = 0.0721311377627509, best validation = 0.15518786758184433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 204/300 [00:06<00:02, 35.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 203: loss training = 0.0720311307481357, best validation = 0.15518786758184433\n",
      "iteration 204: loss training = 0.07107785024813243, best validation = 0.15518786758184433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 208/300 [00:06<00:02, 35.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 205: loss training = 0.07284860419375556, best validation = 0.15518786758184433\n",
      "iteration 206: loss training = 0.07197648925440651, best validation = 0.15518786758184433\n",
      "iteration 207: loss training = 0.07252797271524157, best validation = 0.15518786758184433\n",
      "iteration 208: loss training = 0.07136551822934832, best validation = 0.15518786758184433\n",
      "iteration 209: loss training = 0.07217088767460414, best validation = 0.15518786758184433\n",
      "iteration 210: loss training = 0.07237611285277776, best validation = 0.15518786758184433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 212/300 [00:06<00:02, 35.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 211: loss training = 0.07171704194375447, best validation = 0.15518786758184433\n",
      "iteration 212: loss training = 0.07368254022938865, best validation = 0.15518786758184433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 216/300 [00:06<00:02, 36.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 213: loss training = 0.07214098530156272, best validation = 0.15518786758184433\n",
      "iteration 214: loss training = 0.07185674778052739, best validation = 0.15518786758184433\n",
      "iteration 215: loss training = 0.07139890853847776, best validation = 0.15518786758184433\n",
      "iteration 216: loss training = 0.07294394820928574, best validation = 0.15518786758184433\n",
      "iteration 217: loss training = 0.0717727563210896, best validation = 0.15518786758184433\n",
      "iteration 218: loss training = 0.07212289209876742, best validation = 0.15518786758184433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 220/300 [00:06<00:02, 36.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 219: loss training = 0.07094885941062655, best validation = 0.15518786758184433\n",
      "iteration 220: loss training = 0.07260341942310333, best validation = 0.15518786758184433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 224/300 [00:06<00:02, 36.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 221: loss training = 0.07250763369458062, best validation = 0.15518786758184433\n",
      "iteration 222: loss training = 0.0720510897891862, best validation = 0.15518786758184433\n",
      "iteration 223: loss training = 0.07165216973849706, best validation = 0.15518786758184433\n",
      "iteration 224: loss training = 0.07111153112990516, best validation = 0.15518786758184433\n",
      "iteration 225: loss training = 0.07158486970833369, best validation = 0.15518786758184433\n",
      "iteration 226: loss training = 0.0724652452128274, best validation = 0.15518786758184433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 228/300 [00:06<00:01, 36.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 227: loss training = 0.0730351699250085, best validation = 0.15518786758184433\n",
      "iteration 228: loss training = 0.07294954785278865, best validation = 0.15518786758184433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 232/300 [00:06<00:01, 36.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 229: loss training = 0.07096205864633832, best validation = 0.15518786758184433\n",
      "iteration 230: loss training = 0.07148749487740653, best validation = 0.15518786758184433\n",
      "iteration 231: loss training = 0.07296674379280635, best validation = 0.15518786758184433\n",
      "iteration 232: loss training = 0.07336520403623581, best validation = 0.15518786758184433\n",
      "iteration 233: loss training = 0.07176354740347181, best validation = 0.15518786758184433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 236/300 [00:07<00:01, 33.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 234: loss training = 0.07222269901207515, best validation = 0.15518786758184433\n",
      "iteration 235: loss training = 0.07133712193795613, best validation = 0.15518786758184433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 240/300 [00:07<00:01, 33.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 236: loss training = 0.07215978843825203, best validation = 0.15518786758184433\n",
      "iteration 237: loss training = 0.07090745227677482, best validation = 0.15518786758184433\n",
      "iteration 238: loss training = 0.07093981068049159, best validation = 0.15518786758184433\n",
      "iteration 239: loss training = 0.0727485397032329, best validation = 0.15518786758184433\n",
      "iteration 240: loss training = 0.07274591709886279, best validation = 0.15518786758184433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 244/300 [00:07<00:01, 34.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 241: loss training = 0.07162149463381086, best validation = 0.15518786758184433\n",
      "iteration 242: loss training = 0.07369536906480789, best validation = 0.15518786758184433\n",
      "iteration 243: loss training = 0.07087127385394913, best validation = 0.15518786758184433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 248/300 [00:07<00:01, 34.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 244: loss training = 0.07270032593182155, best validation = 0.15518786758184433\n",
      "iteration 245: loss training = 0.0719010340315955, best validation = 0.15518786758184433\n",
      "iteration 246: loss training = 0.07300271413155965, best validation = 0.15518786758184433\n",
      "iteration 247: loss training = 0.07088334858417511, best validation = 0.15518786758184433\n",
      "iteration 248: loss training = 0.07166227379015513, best validation = 0.15518786758184433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 252/300 [00:07<00:01, 35.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 249: loss training = 0.0725724601319858, best validation = 0.15518786758184433\n",
      "iteration 250: loss training = 0.0718824959227017, best validation = 0.15518786758184433\n",
      "iteration 251: loss training = 0.07184117819581713, best validation = 0.15518786758184433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 256/300 [00:07<00:01, 36.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 252: loss training = 0.07164575691734042, best validation = 0.15518786758184433\n",
      "iteration 253: loss training = 0.07260472008160182, best validation = 0.15518786758184433\n",
      "iteration 254: loss training = 0.07131475848811013, best validation = 0.15518786758184433\n",
      "iteration 255: loss training = 0.0716857271535056, best validation = 0.15518786758184433\n",
      "iteration 256: loss training = 0.07300119634185519, best validation = 0.15518786758184433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 260/300 [00:07<00:01, 36.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 257: loss training = 0.07384849871907916, best validation = 0.15518786758184433\n",
      "iteration 258: loss training = 0.07220964985234397, best validation = 0.15518786758184433\n",
      "iteration 259: loss training = 0.07263603274311338, best validation = 0.15518786758184433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 264/300 [00:07<00:00, 36.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 260: loss training = 0.07137001092944827, best validation = 0.15518786758184433\n",
      "iteration 261: loss training = 0.07205155172518321, best validation = 0.15518786758184433\n",
      "iteration 262: loss training = 0.07342301309108734, best validation = 0.15518786758184433\n",
      "iteration 263: loss training = 0.07138809561729431, best validation = 0.15518786758184433\n",
      "iteration 264: loss training = 0.070515759821449, best validation = 0.15518786758184433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 268/300 [00:07<00:00, 37.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 265: loss training = 0.07242774537631444, best validation = 0.15518786758184433\n",
      "iteration 266: loss training = 0.07131358448948179, best validation = 0.15518786758184433\n",
      "iteration 267: loss training = 0.07303311675786972, best validation = 0.15518786758184433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 272/300 [00:07<00:00, 37.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 268: loss training = 0.07193813153675624, best validation = 0.15518786758184433\n",
      "iteration 269: loss training = 0.07315057143568993, best validation = 0.15518786758184433\n",
      "iteration 270: loss training = 0.07175602657454354, best validation = 0.15518786758184433\n",
      "iteration 271: loss training = 0.07146196173770088, best validation = 0.15518786758184433\n",
      "iteration 272: loss training = 0.07168129831552505, best validation = 0.15518786758184433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 276/300 [00:08<00:00, 37.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 273: loss training = 0.07237080591065544, best validation = 0.15518786758184433\n",
      "iteration 274: loss training = 0.073305786720344, best validation = 0.15518786758184433\n",
      "iteration 275: loss training = 0.07206171644585473, best validation = 0.15518786758184433\n",
      "iteration 276: loss training = 0.07202386962515968, best validation = 0.15518786758184433\n",
      "iteration 277: loss training = 0.07177647948265076, best validation = 0.15518786758184433\n",
      "iteration 278: loss training = 0.07151788366692406, best validation = 0.15518786758184433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 280/300 [00:08<00:00, 31.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 279: loss training = 0.07053190469741821, best validation = 0.15518786758184433\n",
      "iteration 280: loss training = 0.0716434121131897, best validation = 0.15518786758184433\n",
      "iteration 281: loss training = 0.07275648840836116, best validation = 0.15518786758184433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 284/300 [00:08<00:00, 33.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 282: loss training = 0.072214204285826, best validation = 0.15518786758184433\n",
      "iteration 283: loss training = 0.07031467344079699, best validation = 0.15518786758184433\n",
      "iteration 284: loss training = 0.07175058977944511, best validation = 0.15518786758184433\n",
      "iteration 285: loss training = 0.07236948290041514, best validation = 0.15518786758184433\n",
      "iteration 286: loss training = 0.07130766979285649, best validation = 0.15518786758184433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 288/300 [00:08<00:00, 34.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 287: loss training = 0.07171211923871722, best validation = 0.15518786758184433\n",
      "iteration 288: loss training = 0.07242786352123533, best validation = 0.15518786758184433\n",
      "iteration 289: loss training = 0.0720117028270449, best validation = 0.15518786758184433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 292/300 [00:08<00:00, 35.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 290: loss training = 0.0742923596075603, best validation = 0.15518786758184433\n",
      "iteration 291: loss training = 0.07180148895297732, best validation = 0.15518786758184433\n",
      "iteration 292: loss training = 0.07180907151528768, best validation = 0.15518786758184433\n",
      "iteration 293: loss training = 0.07210384522165571, best validation = 0.15518786758184433\n",
      "iteration 294: loss training = 0.07229030025856835, best validation = 0.15518786758184433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 296/300 [00:08<00:00, 36.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 295: loss training = 0.07117915792124611, best validation = 0.15518786758184433\n",
      "iteration 296: loss training = 0.0730367654136249, best validation = 0.15518786758184433\n",
      "iteration 297: loss training = 0.07216800642865044, best validation = 0.15518786758184433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:08<00:00, 34.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 298: loss training = 0.07183263557297843, best validation = 0.15518786758184433\n",
      "iteration 299: loss training = 0.07339294786964144, best validation = 0.15518786758184433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.575290152004787,\n",
       "  0.5230628337178912,\n",
       "  0.5041140913963318,\n",
       "  0.49086094328335356,\n",
       "  0.4691765947001321,\n",
       "  0.4486918108803885,\n",
       "  0.4212984187262399,\n",
       "  0.39928435002054485,\n",
       "  0.369526390518461,\n",
       "  0.3500272716794695,\n",
       "  0.3345822606767927,\n",
       "  0.3133710197040013,\n",
       "  0.30494214381490437,\n",
       "  0.27937967010906767,\n",
       "  0.2627727176461901,\n",
       "  0.25026497883456095,\n",
       "  0.23924501240253448,\n",
       "  0.22595365984099253,\n",
       "  0.2104939477784293,\n",
       "  0.2064917598451887,\n",
       "  0.19517844702516282,\n",
       "  0.18246627066816604,\n",
       "  0.17331779641764505,\n",
       "  0.16754949518612453,\n",
       "  0.1631815071616854,\n",
       "  0.15254596514361246,\n",
       "  0.14381887870175497,\n",
       "  0.1549426657812936,\n",
       "  0.1610946080514363,\n",
       "  0.1534518301486969,\n",
       "  0.13248300552368164,\n",
       "  0.125871727509158,\n",
       "  0.11875968320029122,\n",
       "  0.11395370002303805,\n",
       "  0.11297257031713213,\n",
       "  0.10898739738123757,\n",
       "  0.1078989857009479,\n",
       "  0.10582556469099862,\n",
       "  0.1020444535783359,\n",
       "  0.10236945961202894,\n",
       "  0.09940023933138166,\n",
       "  0.09771742245980672,\n",
       "  0.09717284994465965,\n",
       "  0.09759011438914708,\n",
       "  0.09628841280937195,\n",
       "  0.09626735108239311,\n",
       "  0.09479719613279615,\n",
       "  0.0924577649150576,\n",
       "  0.09190578013658524,\n",
       "  0.09019143240792411,\n",
       "  0.09050844183989934,\n",
       "  0.08796270830290658,\n",
       "  0.08815826049872807,\n",
       "  0.08661599457263947,\n",
       "  0.08668576180934906,\n",
       "  0.08836132075105395,\n",
       "  0.08443488074200493,\n",
       "  0.08491875550576619,\n",
       "  0.08451614316020693,\n",
       "  0.08474647998809814,\n",
       "  0.0823140378509249,\n",
       "  0.08022492698260716,\n",
       "  0.07878885418176651,\n",
       "  0.07925485074520111,\n",
       "  0.07746279665402003,\n",
       "  0.07761583370821816,\n",
       "  0.07659087755850383,\n",
       "  0.0779504297035081,\n",
       "  0.07734409613268715,\n",
       "  0.07812984713486262,\n",
       "  0.07589581928082875,\n",
       "  0.07536151047263827,\n",
       "  0.07712305337190628,\n",
       "  0.07616574742964335,\n",
       "  0.07490397564002446,\n",
       "  0.07518224950347628,\n",
       "  0.07534153014421463,\n",
       "  0.07578128895589284,\n",
       "  0.0750511395079749,\n",
       "  0.07512409559317998,\n",
       "  0.07687919586896896,\n",
       "  0.0759180241397449,\n",
       "  0.0760098227432796,\n",
       "  0.07471464042152677,\n",
       "  0.07406539150646754,\n",
       "  0.07423896661826543,\n",
       "  0.07561293563672475,\n",
       "  0.07449083988155637,\n",
       "  0.07413456695420402,\n",
       "  0.07280060169952256,\n",
       "  0.07356831324951989,\n",
       "  0.0737442257148879,\n",
       "  0.0727660304733685,\n",
       "  0.07278582666601453,\n",
       "  0.0724650312747274,\n",
       "  0.07396888732910156,\n",
       "  0.07383297596658979,\n",
       "  0.07362606908593859,\n",
       "  0.07465571484395436,\n",
       "  0.07326418587139674,\n",
       "  0.07260005176067352,\n",
       "  0.07299762006316866,\n",
       "  0.07339955759899956,\n",
       "  0.07229577749967575,\n",
       "  0.07187507408005851,\n",
       "  0.07342934714896339,\n",
       "  0.07220896439892906,\n",
       "  0.07349256638969694,\n",
       "  0.07284632963793618,\n",
       "  0.07299777013914925,\n",
       "  0.07299882386411939,\n",
       "  0.07144812015550477,\n",
       "  0.07353551685810089,\n",
       "  0.072867109307221,\n",
       "  0.0725016061748777,\n",
       "  0.07307511674506324,\n",
       "  0.07253750094345637,\n",
       "  0.07138203403779439,\n",
       "  0.07266807236841746,\n",
       "  0.07164516087089266,\n",
       "  0.07387702486344747,\n",
       "  0.07223169505596161,\n",
       "  0.07163260557821818,\n",
       "  0.0715841640319143,\n",
       "  0.0716453662940434,\n",
       "  0.07284687459468842,\n",
       "  0.07193449884653091,\n",
       "  0.07207453463758741,\n",
       "  0.07190864852496556,\n",
       "  0.07116275812898364,\n",
       "  0.07276767918041774,\n",
       "  0.07251773455313273,\n",
       "  0.07213300785848073,\n",
       "  0.07140689236777169,\n",
       "  0.07325071415730885,\n",
       "  0.07180818915367126,\n",
       "  0.07231793339763369,\n",
       "  0.07324156803744179,\n",
       "  0.07316202138151441,\n",
       "  0.0707452403647559,\n",
       "  0.07153690819229398,\n",
       "  0.07233368498938424,\n",
       "  0.0724339070064681,\n",
       "  0.07262960289205823,\n",
       "  0.07299315610102244,\n",
       "  0.07187151376690183,\n",
       "  0.07359055961881365,\n",
       "  0.07297112792730331,\n",
       "  0.07335166846002851,\n",
       "  0.0727966810975756,\n",
       "  0.07154869926827294,\n",
       "  0.07164907029696874,\n",
       "  0.07344281886305128,\n",
       "  0.0727457446711404,\n",
       "  0.07200802756207329,\n",
       "  0.07291985941784722,\n",
       "  0.07153021437781197,\n",
       "  0.07424401066132955,\n",
       "  0.07194850806679044,\n",
       "  0.07066672987171582,\n",
       "  0.07131297247750419,\n",
       "  0.07250082279954638,\n",
       "  0.07229153705494744,\n",
       "  0.07235017205987658,\n",
       "  0.07178971277815956,\n",
       "  0.0710394520844732,\n",
       "  0.07302692319665637,\n",
       "  0.07277927760566984,\n",
       "  0.07227397284337453,\n",
       "  0.07156947361571449,\n",
       "  0.07168517155306679,\n",
       "  0.07245001303298133,\n",
       "  0.0715297396693911,\n",
       "  0.07319753084863935,\n",
       "  0.07225197234324046,\n",
       "  0.07292928546667099,\n",
       "  0.07044703513383865,\n",
       "  0.07427361075367246,\n",
       "  0.07201183480875832,\n",
       "  0.07274116895028523,\n",
       "  0.07126408496073314,\n",
       "  0.07269219521965299,\n",
       "  0.07188296743801662,\n",
       "  0.07181128433772496,\n",
       "  0.0724478353347097,\n",
       "  0.07182850156511579,\n",
       "  0.0730134706412043,\n",
       "  0.07293280639818736,\n",
       "  0.0720451261316027,\n",
       "  0.07129467598029546,\n",
       "  0.07029998089585986,\n",
       "  0.07275629469326564,\n",
       "  0.0715107513325555,\n",
       "  0.07172681497676033,\n",
       "  0.07235914468765259,\n",
       "  0.07183409482240677,\n",
       "  0.07243814106498446,\n",
       "  0.07376462540456227,\n",
       "  0.07163174769708089,\n",
       "  0.07147658403430666,\n",
       "  0.07202456040041787,\n",
       "  0.07056256649749619,\n",
       "  0.0721311377627509,\n",
       "  0.0720311307481357,\n",
       "  0.07107785024813243,\n",
       "  0.07284860419375556,\n",
       "  0.07197648925440651,\n",
       "  0.07252797271524157,\n",
       "  0.07136551822934832,\n",
       "  0.07217088767460414,\n",
       "  0.07237611285277776,\n",
       "  0.07171704194375447,\n",
       "  0.07368254022938865,\n",
       "  0.07214098530156272,\n",
       "  0.07185674778052739,\n",
       "  0.07139890853847776,\n",
       "  0.07294394820928574,\n",
       "  0.0717727563210896,\n",
       "  0.07212289209876742,\n",
       "  0.07094885941062655,\n",
       "  0.07260341942310333,\n",
       "  0.07250763369458062,\n",
       "  0.0720510897891862,\n",
       "  0.07165216973849706,\n",
       "  0.07111153112990516,\n",
       "  0.07158486970833369,\n",
       "  0.0724652452128274,\n",
       "  0.0730351699250085,\n",
       "  0.07294954785278865,\n",
       "  0.07096205864633832,\n",
       "  0.07148749487740653,\n",
       "  0.07296674379280635,\n",
       "  0.07336520403623581,\n",
       "  0.07176354740347181,\n",
       "  0.07222269901207515,\n",
       "  0.07133712193795613,\n",
       "  0.07215978843825203,\n",
       "  0.07090745227677482,\n",
       "  0.07093981068049159,\n",
       "  0.0727485397032329,\n",
       "  0.07274591709886279,\n",
       "  0.07162149463381086,\n",
       "  0.07369536906480789,\n",
       "  0.07087127385394913,\n",
       "  0.07270032593182155,\n",
       "  0.0719010340315955,\n",
       "  0.07300271413155965,\n",
       "  0.07088334858417511,\n",
       "  0.07166227379015513,\n",
       "  0.0725724601319858,\n",
       "  0.0718824959227017,\n",
       "  0.07184117819581713,\n",
       "  0.07164575691734042,\n",
       "  0.07260472008160182,\n",
       "  0.07131475848811013,\n",
       "  0.0716857271535056,\n",
       "  0.07300119634185519,\n",
       "  0.07384849871907916,\n",
       "  0.07220964985234397,\n",
       "  0.07263603274311338,\n",
       "  0.07137001092944827,\n",
       "  0.07205155172518321,\n",
       "  0.07342301309108734,\n",
       "  0.07138809561729431,\n",
       "  0.070515759821449,\n",
       "  0.07242774537631444,\n",
       "  0.07131358448948179,\n",
       "  0.07303311675786972,\n",
       "  0.07193813153675624,\n",
       "  0.07315057143568993,\n",
       "  0.07175602657454354,\n",
       "  0.07146196173770088,\n",
       "  0.07168129831552505,\n",
       "  0.07237080591065544,\n",
       "  0.073305786720344,\n",
       "  0.07206171644585473,\n",
       "  0.07202386962515968,\n",
       "  0.07177647948265076,\n",
       "  0.07151788366692406,\n",
       "  0.07053190469741821,\n",
       "  0.0716434121131897,\n",
       "  0.07275648840836116,\n",
       "  0.072214204285826,\n",
       "  0.07031467344079699,\n",
       "  0.07175058977944511,\n",
       "  0.07236948290041514,\n",
       "  0.07130766979285649,\n",
       "  0.07171211923871722,\n",
       "  0.07242786352123533,\n",
       "  0.0720117028270449,\n",
       "  0.0742923596075603,\n",
       "  0.07180148895297732,\n",
       "  0.07180907151528768,\n",
       "  0.07210384522165571,\n",
       "  0.07229030025856835,\n",
       "  0.07117915792124611,\n",
       "  0.0730367654136249,\n",
       "  0.07216800642865044,\n",
       "  0.07183263557297843,\n",
       "  0.07339294786964144],\n",
       " [0.5184966176748276,\n",
       "  0.5155826807022095,\n",
       "  0.5007872879505157,\n",
       "  0.47202466428279877,\n",
       "  0.46458882093429565,\n",
       "  0.4442215859889984,\n",
       "  0.41944898664951324,\n",
       "  0.40270404517650604,\n",
       "  0.3797880858182907,\n",
       "  0.36804574728012085,\n",
       "  0.3601859211921692,\n",
       "  0.33271245658397675,\n",
       "  0.3246709257364273,\n",
       "  0.3094460219144821,\n",
       "  0.3044036328792572,\n",
       "  0.30107082426548004,\n",
       "  0.2818908840417862,\n",
       "  0.2693510502576828,\n",
       "  0.26030271500349045,\n",
       "  0.2646048665046692,\n",
       "  0.23973448574543,\n",
       "  0.2287551462650299,\n",
       "  0.22797898203134537,\n",
       "  0.22980256378650665,\n",
       "  0.20941660553216934,\n",
       "  0.19675160199403763,\n",
       "  0.20252937078475952,\n",
       "  0.209518164396286,\n",
       "  0.1854076012969017,\n",
       "  0.1913171112537384,\n",
       "  0.18095802515745163,\n",
       "  0.17522932589054108,\n",
       "  0.171552374958992,\n",
       "  0.17030829191207886,\n",
       "  0.17078828066587448,\n",
       "  0.16918162256479263,\n",
       "  0.1698593944311142,\n",
       "  0.16778786480426788,\n",
       "  0.16930148005485535,\n",
       "  0.16356462985277176,\n",
       "  0.16605931520462036,\n",
       "  0.16327181458473206,\n",
       "  0.16675472259521484,\n",
       "  0.1626342311501503,\n",
       "  0.16428079456090927,\n",
       "  0.16581325232982635,\n",
       "  0.16205324977636337,\n",
       "  0.16250897198915482,\n",
       "  0.16339220106601715,\n",
       "  0.16276346892118454,\n",
       "  0.16190502047538757,\n",
       "  0.16056329756975174,\n",
       "  0.1604316085577011,\n",
       "  0.16001196950674057,\n",
       "  0.16083403676748276,\n",
       "  0.16013702005147934,\n",
       "  0.1588771864771843,\n",
       "  0.1594662070274353,\n",
       "  0.1582939401268959,\n",
       "  0.16033044457435608,\n",
       "  0.15855304896831512,\n",
       "  0.1585530936717987,\n",
       "  0.15800585597753525,\n",
       "  0.15755242854356766,\n",
       "  0.1575174406170845,\n",
       "  0.1576680839061737,\n",
       "  0.1575186625123024,\n",
       "  0.1572900265455246,\n",
       "  0.1573919653892517,\n",
       "  0.15740568935871124,\n",
       "  0.1569761112332344,\n",
       "  0.15773850679397583,\n",
       "  0.1570495292544365,\n",
       "  0.1568555161356926,\n",
       "  0.15669476985931396,\n",
       "  0.15649963915348053,\n",
       "  0.15695960074663162,\n",
       "  0.156425841152668,\n",
       "  0.15636491775512695,\n",
       "  0.1565558910369873,\n",
       "  0.15650715678930283,\n",
       "  0.15657518059015274,\n",
       "  0.15633992105722427,\n",
       "  0.15692908316850662,\n",
       "  0.15600571781396866,\n",
       "  0.1560826152563095,\n",
       "  0.15610682219266891,\n",
       "  0.1558568924665451,\n",
       "  0.15518786758184433,\n",
       "  0.1565123274922371,\n",
       "  0.15579475462436676,\n",
       "  0.1554911658167839,\n",
       "  0.15564711391925812,\n",
       "  0.15567003190517426,\n",
       "  0.15564417093992233,\n",
       "  0.15564342588186264,\n",
       "  0.15567506849765778,\n",
       "  0.15564829856157303,\n",
       "  0.15555306524038315,\n",
       "  0.15554533898830414,\n",
       "  0.1555178537964821,\n",
       "  0.15552730113267899,\n",
       "  0.1555359959602356,\n",
       "  0.1555655226111412,\n",
       "  0.15546374022960663,\n",
       "  0.15553376078605652,\n",
       "  0.1557285040616989,\n",
       "  0.15555483102798462,\n",
       "  0.15559136122465134,\n",
       "  0.15558639913797379,\n",
       "  0.15556908398866653,\n",
       "  0.15549486130475998,\n",
       "  0.15558039397001266,\n",
       "  0.15557190775871277,\n",
       "  0.15545231103897095,\n",
       "  0.15526845306158066,\n",
       "  0.1554279774427414,\n",
       "  0.15550392121076584,\n",
       "  0.15553759783506393,\n",
       "  0.1554597094655037,\n",
       "  0.15544811636209488,\n",
       "  0.15545782446861267,\n",
       "  0.15549588948488235,\n",
       "  0.1555139273405075,\n",
       "  0.15548691153526306,\n",
       "  0.15547161549329758,\n",
       "  0.1554803028702736,\n",
       "  0.15542367100715637,\n",
       "  0.155389666557312,\n",
       "  0.15539351850748062,\n",
       "  0.15542607754468918,\n",
       "  0.1554398238658905,\n",
       "  0.15546536445617676,\n",
       "  0.15546274930238724,\n",
       "  0.1554199531674385,\n",
       "  0.1553807333111763,\n",
       "  0.15537139773368835,\n",
       "  0.15538639575242996,\n",
       "  0.15540861338377,\n",
       "  0.15538375079631805,\n",
       "  0.15539681911468506,\n",
       "  0.15540555119514465,\n",
       "  0.15539365261793137,\n",
       "  0.15542630851268768,\n",
       "  0.15539266914129257,\n",
       "  0.1553707793354988,\n",
       "  0.15537065267562866,\n",
       "  0.155343696475029,\n",
       "  0.15537700802087784,\n",
       "  0.15539661794900894,\n",
       "  0.15539703518152237,\n",
       "  0.15539198368787766,\n",
       "  0.15538433194160461,\n",
       "  0.15538320690393448,\n",
       "  0.15537923574447632,\n",
       "  0.15537676215171814,\n",
       "  0.1553751900792122,\n",
       "  0.15537402033805847,\n",
       "  0.15536821633577347,\n",
       "  0.15537001937627792,\n",
       "  0.15536043792963028,\n",
       "  0.15535544604063034,\n",
       "  0.1553630605340004,\n",
       "  0.15536124259233475,\n",
       "  0.1553610935807228,\n",
       "  0.15535881370306015,\n",
       "  0.15535665303468704,\n",
       "  0.15534958243370056,\n",
       "  0.1553451344370842,\n",
       "  0.1553480252623558,\n",
       "  0.15535256266593933,\n",
       "  0.1553495079278946,\n",
       "  0.15535230189561844,\n",
       "  0.15535516291856766,\n",
       "  0.15536148101091385,\n",
       "  0.15536560118198395,\n",
       "  0.15536730736494064,\n",
       "  0.15536775439977646,\n",
       "  0.15537364780902863,\n",
       "  0.1553800255060196,\n",
       "  0.15537942200899124,\n",
       "  0.1553785353899002,\n",
       "  0.15537789463996887,\n",
       "  0.1553773432970047,\n",
       "  0.1553749293088913,\n",
       "  0.1553734540939331,\n",
       "  0.15537284314632416,\n",
       "  0.15537142753601074,\n",
       "  0.15536947548389435,\n",
       "  0.15536897629499435,\n",
       "  0.15536829829216003,\n",
       "  0.15536829829216003,\n",
       "  0.15536650270223618,\n",
       "  0.15536584705114365,\n",
       "  0.15536537766456604,\n",
       "  0.1553647816181183,\n",
       "  0.15536514669656754,\n",
       "  0.15536411106586456,\n",
       "  0.15536364167928696,\n",
       "  0.15536358952522278,\n",
       "  0.15536432713270187,\n",
       "  0.15536494553089142,\n",
       "  0.15536418557167053,\n",
       "  0.15536288172006607,\n",
       "  0.1553613841533661,\n",
       "  0.15536124259233475,\n",
       "  0.15535918623209,\n",
       "  0.15535858273506165,\n",
       "  0.15535694360733032,\n",
       "  0.15535763651132584,\n",
       "  0.15535780787467957,\n",
       "  0.15535811334848404,\n",
       "  0.15535828471183777,\n",
       "  0.15535864979028702,\n",
       "  0.15535901486873627,\n",
       "  0.15535932034254074,\n",
       "  0.15535923093557358,\n",
       "  0.1553593948483467,\n",
       "  0.15535960346460342,\n",
       "  0.15535961836576462,\n",
       "  0.15535952895879745,\n",
       "  0.1553594395518303,\n",
       "  0.15535947680473328,\n",
       "  0.15535911172628403,\n",
       "  0.15535857528448105,\n",
       "  0.15535838901996613,\n",
       "  0.15535817295312881,\n",
       "  0.15535803884267807,\n",
       "  0.15535816550254822,\n",
       "  0.15535818785429,\n",
       "  0.15535860508680344,\n",
       "  0.15535882115364075,\n",
       "  0.1553592011332512,\n",
       "  0.15535929054021835,\n",
       "  0.15535935759544373,\n",
       "  0.15535925328731537,\n",
       "  0.15535926818847656,\n",
       "  0.1553594395518303,\n",
       "  0.1553598865866661,\n",
       "  0.1553596705198288,\n",
       "  0.1553596630692482,\n",
       "  0.15535971522331238,\n",
       "  0.15535975247621536,\n",
       "  0.15535973757505417,\n",
       "  0.1553596928715706,\n",
       "  0.155359648168087,\n",
       "  0.15535961836576462,\n",
       "  0.15535961836576462,\n",
       "  0.155359648168087,\n",
       "  0.15535961836576462,\n",
       "  0.15535955876111984,\n",
       "  0.15535953640937805,\n",
       "  0.15535947680473328,\n",
       "  0.15535948425531387,\n",
       "  0.15535956621170044,\n",
       "  0.15535956621170044,\n",
       "  0.15535958856344223,\n",
       "  0.15535959601402283,\n",
       "  0.15535955131053925,\n",
       "  0.15535948425531387,\n",
       "  0.15535948425531387,\n",
       "  0.1553594321012497,\n",
       "  0.1553594395518303,\n",
       "  0.1553594097495079,\n",
       "  0.1553594022989273,\n",
       "  0.1553593948483467,\n",
       "  0.1553593873977661,\n",
       "  0.1553594022989273,\n",
       "  0.1553594172000885,\n",
       "  0.15535945445299149,\n",
       "  0.15535945445299149,\n",
       "  0.15535945445299149,\n",
       "  0.15535945445299149,\n",
       "  0.1553594470024109,\n",
       "  0.15535945445299149,\n",
       "  0.15535945445299149,\n",
       "  0.15535945445299149,\n",
       "  0.15535945445299149,\n",
       "  0.1553594470024109,\n",
       "  0.15535946190357208,\n",
       "  0.15535946190357208,\n",
       "  0.15535945445299149,\n",
       "  0.15535946190357208,\n",
       "  0.15535946190357208,\n",
       "  0.15535945445299149,\n",
       "  0.15535946190357208,\n",
       "  0.15535945445299149,\n",
       "  0.15535945445299149,\n",
       "  0.1553594470024109,\n",
       "  0.15535945445299149,\n",
       "  0.1553594470024109,\n",
       "  0.15535945445299149,\n",
       "  0.1553594470024109,\n",
       "  0.1553594395518303,\n",
       "  0.15535945445299149,\n",
       "  0.1553594470024109,\n",
       "  0.1553594470024109,\n",
       "  0.1553594470024109,\n",
       "  0.15535945445299149,\n",
       "  0.1553594470024109])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn = RNN(m, d, dev)\n",
    "train(rnn, nbEpoches, lr, wd, train_loader, valid_loader, path+'rnn_'+str(snr)+'dB_ula.pth', train_func, valid_func)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
